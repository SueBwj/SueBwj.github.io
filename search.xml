<?xml version="1.0" encoding="utf-8"?>
<search> 
  
  
    
    <entry>
      <title>2024-5-26</title>
      <link href="/2024/05/26/2024-5-26/"/>
      <url>/2024/05/26/2024-5-26/</url>
      
        <content type="html"><![CDATA[<div class="hbe hbe-container" id="hexo-blog-encrypt" data-wpm="Oh, this is an invalid password. Check and try again, please." data-whm="OOPS, these decrypted content may changed, but you can still have a look.">  <script id="hbeData" type="hbeData" data-hmacdigest="b9790bd6677a9766d1cf1068a948378b7e5185e35161d18c52e220b831daf626">881edb0fb107383b53380806f31bae93f2538c782685500886ce42a0346b30cff5b7c3d430b2c2140fe89e87bcb2b5fd2dece64dc7589bd0ee3eb8136e91f3f7bdba8f3e787bb5d35ae40df15e4e98e2482973b6bfaa846936a6bc5f0145869d64263533f1b7156219462d36c759b5354b40c50dcc101533ffc7d3024c72abaedabb5933271ff55e31b8b51979c8128dae2d83c7f2f60baf2e06aae30653cbd9d92a979367c47a9ef95368eccfea4af0f47b94ca969e66a8003d9011d56ff9cdca41739193696ffb7062b4cb953edbc01a25b59366797d5ecdc1db50ea589f88343c9a7d9c1aaf78d0e195c02f9ec9eba43b329f4366de1f4f8e42906e13da7c3f6b4cde549df8435014618587d29d64</script>  <div class="hbe hbe-content">    <div class="hbe hbe-input hbe-input-wave">      <input class="hbe hbe-input-field hbe-input-field-wave" type="password" id="hbePass">      <label class="hbe hbe-input-label hbe-input-label-wave" for="hbePass">        <span class="hbe hbe-input-label-content hbe-input-label-content-wave">Hey, password is required here.</span>      </label>      <svg class="hbe hbe-graphic hbe-graphic-wave" width="300%" height="100%" viewBox="0 0 1200 60" preserveAspectRatio="none">        <path d="M0,56.5c0,0,298.666,0,399.333,0C448.336,56.5,513.994,46,597,46c77.327,0,135,10.5,200.999,10.5c95.996,0,402.001,0,402.001,0"></path>      </svg>    </div>  </div></div><script data-pjax src="/lib/hbe.js"></script><link href="/css/hbe.style.css" rel="stylesheet" type="text/css">]]></content>
      
      
      
        <tags>
            
            <tag> 日记 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>2024-5-26</title>
      <link href="/2024/05/26/2024-5-27/"/>
      <url>/2024/05/26/2024-5-27/</url>
      
        <content type="html"><![CDATA[<div class="hbe hbe-container" id="hexo-blog-encrypt" data-wpm="Oh, this is an invalid password. Check and try again, please." data-whm="OOPS, these decrypted content may changed, but you can still have a look.">  <script id="hbeData" type="hbeData" data-hmacdigest="78621c093713a1feae60cde8719366d6fe5f50f96705689e774752ed42ca4b35">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</script>  <div class="hbe hbe-content">    <div class="hbe hbe-input hbe-input-wave">      <input class="hbe hbe-input-field hbe-input-field-wave" type="password" id="hbePass">      <label class="hbe hbe-input-label hbe-input-label-wave" for="hbePass">        <span class="hbe hbe-input-label-content hbe-input-label-content-wave">Hey, password is required here.</span>      </label>      <svg class="hbe hbe-graphic hbe-graphic-wave" width="300%" height="100%" viewBox="0 0 1200 60" preserveAspectRatio="none">        <path d="M0,56.5c0,0,298.666,0,399.333,0C448.336,56.5,513.994,46,597,46c77.327,0,135,10.5,200.999,10.5c95.996,0,402.001,0,402.001,0"></path>      </svg>    </div>  </div></div><script data-pjax src="/lib/hbe.js"></script><link href="/css/hbe.style.css" rel="stylesheet" type="text/css">]]></content>
      
      
      
        <tags>
            
            <tag> 日记 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>文本分析</title>
      <link href="/2024/05/26/%E6%96%87%E6%9C%AC%E5%88%86%E6%9E%90/"/>
      <url>/2024/05/26/%E6%96%87%E6%9C%AC%E5%88%86%E6%9E%90/</url>
      
        <content type="html"><![CDATA[<h3 id="文本分析"><a href="#文本分析" class="headerlink" title="文本分析"></a>文本分析</h3><p>由于文本数据往往无法直接对比和计算，所以在对其进行分析之前，通常需要将它们处理为一个个更基本的单元</p><ul><li>段 比较难度高</li><li>句 比较难度高</li><li>词 ✔️</li><li>字 可以直接对比，但是不能包含语义，且有歧义</li></ul><h3 id="文本切词"><a href="#文本切词" class="headerlink" title="文本切词"></a>文本切词</h3><ol><li>英语：将标点符号香换为空格，空格为分隔符</li><li>中文：句子中各个词之间没有具体的标识，需要对句子成分进行分析以确定其如何切分</li></ol><h3 id="文本过滤内容"><a href="#文本过滤内容" class="headerlink" title="文本过滤内容"></a>文本过滤内容</h3><ol><li>符号类：标点符号、特殊符号。比如换行、换页或者表情符号等</li><li>无意义的词：一些常用的副词、连接词等。例如“的”“得”“地”“了“等</li><li>上下文中无意义的高频词：分析特定事件帖子中的话题分布，与事件名称相关的词语可能在所有话题中都频率很高，其存在会影响话题分布的分析</li></ol><p><img src="/../%E6%96%87%E6%9C%AC%E5%88%86%E6%9E%90/Untitled.png" alt="Untitled"></p><h3 id="保留固定搭配词语"><a href="#保留固定搭配词语" class="headerlink" title="保留固定搭配词语"></a>保留固定搭配词语</h3><ul><li>用户增加自定义词典<br>如果不增加一些自定义词语可能会造成如下的一些歧义产生<ul><li>讨论&#x2F;战争&#x2F;与&#x2F;和平&#x2F;等&#x2F;问题</li><li>讨论&#x2F;战争&#x2F;与&#x2F;和&#x2F;平等&#x2F;问题</li><li>新能源汽车</li><li>新能源&#x2F;汽车</li></ul></li></ul><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> jieba</span><br><span class="line"></span><br><span class="line">text = <span class="string">&#x27;中山大学是伟大的民族英雄、伟大的爱国主义者、中国民主革命的伟大先驱孙中山先生于1924年亲手&#x27;</span>\</span><br><span class="line">    <span class="string">&#x27;创办，中国共产党早期领导人共同创建的大学，是中国传播马克思主义的重要发源地之一，具有优良&#x27;</span>\</span><br><span class="line">    <span class="string">&#x27;革命传统、鲜亮红色基因和卓越品格追求。中山大学起初校名为国立广东大学。孙中山先生逝世后，&#x27;</span>\</span><br><span class="line">    <span class="string">&#x27;学校于1926年定名为国立中山大学。&#x27;</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 设置自定义词典</span></span><br><span class="line">jieba.load_userdict(<span class="string">&#x27;userdict.txt&#x27;</span>)</span><br><span class="line"><span class="comment"># 避免一个专有词语被切割,如果专用词语过多，就采用第一种方法，将所有的专有词语存储在字典之中</span></span><br><span class="line">jieba.suggest_freq(<span class="string">&#x27;国立广东大学&#x27;</span>, <span class="literal">True</span>)</span><br><span class="line">jieba.suggest_freq(<span class="string">&#x27;国立中山大学&#x27;</span>, <span class="literal">True</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 切词，并且在过程中过滤掉停用词</span></span><br><span class="line">segList = jieba.cut(text, use_paddle=<span class="literal">True</span>)</span><br><span class="line"></span><br><span class="line">filteredSegList = []</span><br><span class="line"></span><br><span class="line"><span class="comment"># 将stopwords存储为一个列表</span></span><br><span class="line">stopwords = <span class="built_in">open</span>(<span class="string">&#x27;stop_words.txt&#x27;</span>, encoding=<span class="string">&#x27;UTF-8&#x27;</span>).readlines()</span><br><span class="line"></span><br><span class="line"><span class="keyword">for</span> word <span class="keyword">in</span> segList:</span><br><span class="line">    <span class="keyword">if</span> word+<span class="string">&#x27;\n&#x27;</span> <span class="keyword">not</span> <span class="keyword">in</span> stopwords:</span><br><span class="line">        filteredSegList.append(word)</span><br><span class="line">    <span class="keyword">else</span>:</span><br><span class="line">        <span class="built_in">print</span>(word, end=<span class="string">&#x27; &#x27;</span>)</span><br><span class="line"><span class="built_in">print</span>(<span class="string">&quot;\n切词结果: &quot;</span>, filteredSegList)</span><br></pre></td></tr></table></figure><h3 id="关键词提取"><a href="#关键词提取" class="headerlink" title="关键词提取"></a>关键词提取</h3><p>关键词提取通常是面向较长的文本去提取具有代表性的词语，使得人们可以从这些词语了解文本的主题和内容，可以用于支持文本比较、内容分类、主题分析等</p><ul><li>提取方法<ul><li>实词<br><img src="/../%E6%96%87%E6%9C%AC%E5%88%86%E6%9E%90/Untitled%201.png" alt="Untitled"></li><li>虚词<br><img src="/../%E6%96%87%E6%9C%AC%E5%88%86%E6%9E%90/Untitled%202.png" alt="Untitled"><br><img src="/../%E6%96%87%E6%9C%AC%E5%88%86%E6%9E%90/Untitled%203.png" alt="jieba包中筛选所需要的特定词性的词语"><br>jieba 包中筛选所需要的特定词性的词语</li></ul></li><li>实词包含更多的实际意义，虚词包含语义不多</li></ul><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> jieba</span><br><span class="line"><span class="keyword">import</span> jieba.posseg <span class="keyword">as</span> pseg</span><br><span class="line"></span><br><span class="line">text = <span class="string">&#x27;中山大学是伟大的民族英推、伟大的爱国主义者、中国民主革命的伟大先驱孙中山先生于1924年亲手创办，中国共产党早期领导人共同创建的大学，是中国传播马克思主义的重要发源地之一，具有优良革命传统、鲜亮红色基因和卓越品格追求。中山大学起初校名为国立广东大学。孙中山先生逝世后，学校于1926年定名为国立中山大学。&#x27;</span>\</span><br><span class="line">    <span class="string">&#x27;今日的中山大学，由1952年院系调整后分设的中山大学和中山医科大学于2001年10月合井而成。通过部省共建，在国家、地方和社会的大力支持下，中山大学成为一所国内一流、国际知名的现代综合性大学，形成了综合性、研究型、开放式的办学特质。在近百年的办学历史中，中山大学汇聚一大批蜚声海内外的名家大师，学术文脉积淀深厚。邓植仪、丁颖、冯友兰、郭沫若.鲁迅、傅斯年、顾颉刚、商承祚、何思敬、赵元任、周谷城、梁伯强、蒲蛰龙、王亚南、刘节、岑仲勉、王起、柯、陈寅恪、姜立夫、杨荣国、梁方仲、容庚、高兆兰、谢志光、陈耀真、陈心陶、林树模、秦光煜、钟世藩、周寿恺、董每戡、戴镏龄、高由福等著名学者先后在本校任教。近年来，中山大学吸引集聚了一大批海内外优秀的学术英才，奋斗在教学和科研第一线，致力于培养更多更优秀的社会主义事业建设者和接班人。&#x27;</span>\</span><br><span class="line">    <span class="string">&#x27;1999年9月，珠海市人民政府与中山大学正式签署合作建设中山大学珠海校区协议书&#x27;</span>\</span><br><span class="line">    <span class="string">&#x27;2000年1月，教育部批复同意建设中山大学珠海校区。2015年9月，深圳市人民政府与中山大学签署合作举办中山大学深圳校区的备志录&#x27;</span>\</span><br><span class="line">    <span class="string">&#x27;同年12月，获教育部批复同意建设深圳校区。至此，中山大学形成了三校区五校园统筹发展的办学格局，在广州、珠海、深圳扎根办学，各校区统筹规划、错位发展，三校区五校园共同支撑中山大学高质量内涵式发展。&#x27;</span>\</span><br><span class="line">    <span class="string">&#x27;近年来，中山大学在加强文理医传统优势学科的基础上，努力补齐工科短板，填补了农学、艺术学空白，学科门类更加齐全，形成了文理医工农艺综合发展的学科格局。广州校区重点提升文、理、医传统优势学科，珠海校区重点发展深海、深空、深地、深蓝学科群，深圳校区着力发展新医科、新工科、新农科，学校综合性办学优势和特色愈发凸显，学科实力居于国内高校前列。&#x27;</span>\</span><br><span class="line">    <span class="string">&#x27;中山大学人文社会科学以习近平新时代中国特色社会主义思想为指导，坚持“四个面向”，积极倡导“出思想、出理论、出学派”&#x27;</span>\</span><br><span class="line">    <span class="string">&#x27;学科与科研规划聚焦国家重大战略，服务区域社会经济发展需求，紧握粤港澳大湾区建设重要机遇，进一步推进有组织科研，推动跨学科交叉融合发展，激发人文社科发展新动能，为加快建构中国自主的知识体系责献中大力量。&#x27;</span>\</span><br><span class="line">    <span class="string">&#x27;中山大学医科有着悠久的历史和卓越的实力，我国最早的西医教育诞生于此。目前，中山大学医学教育教学改革深入推进，医学科研创新日新月异，拥有10家直属附属医院，构建了门类齐全、实力雄厚、技术领先、设备先进、优势互补、具有强烈社会责任意识的医疗教治服务网络体系，医教研综合实力、医疗服务能力与规模居于全国领先行列。&#x27;</span></span><br><span class="line"></span><br><span class="line">counter = &#123;&#125;</span><br><span class="line"><span class="comment"># 切词并进行词性标注</span></span><br><span class="line">segList = pseg.cut(text)</span><br><span class="line"></span><br><span class="line"><span class="keyword">for</span> word, flag <span class="keyword">in</span> segList:</span><br><span class="line">    <span class="comment"># 判断词语是否符合某个词性</span></span><br><span class="line">    <span class="keyword">if</span> flag <span class="keyword">in</span> <span class="string">&#x27;nva&#x27;</span>:  <span class="comment"># 只选择名词，动词，形容词</span></span><br><span class="line">        <span class="keyword">if</span> word <span class="keyword">in</span> counter.keys():</span><br><span class="line">            counter[word] += <span class="number">1</span></span><br><span class="line">        <span class="keyword">else</span>:</span><br><span class="line">            counter.update(&#123;word: <span class="number">1</span>&#125;)</span><br><span class="line"></span><br><span class="line">freqWrods = <span class="built_in">list</span>(counter.items())</span><br><span class="line">freqWrods.sort(key=<span class="keyword">lambda</span> x: x[<span class="number">1</span>], reverse=<span class="literal">True</span>)</span><br><span class="line"><span class="built_in">print</span>(freqWrods)</span><br><span class="line"></span><br></pre></td></tr></table></figure><h3 id="关键词提取算法"><a href="#关键词提取算法" class="headerlink" title="关键词提取算法"></a>关键词提取算法</h3><ul><li>TF-IDF 算法<br>TF: 词频、 IDF：逆文档频率<br>如果一个词语在当前文档中出现很多，但是在其他文档中出现很少，就说明这个词语可能是这篇文档的一个重要特征<br><img src="/../%E6%96%87%E6%9C%AC%E5%88%86%E6%9E%90/Untitled%204.png" alt="Untitled"></li><li>TextRank 算法<br>TextRank 是一种用于自然语言处理的文本摘要和关键词提取算法，它是基于 PageRank 算法的一种无监督图算法。<ul><li><strong>应用</strong><br>TextRank 算法广泛应用于各种自然语言处理任务，例如自动摘要、关键词提取、文本分类等，因其无需人工标注数据且效果较好而受到广泛关注。</li></ul></li></ul><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> jieba.analyse</span><br><span class="line">text = <span class="built_in">open</span>(<span class="string">&#x27;牧羊少年奇幻之旅.txt&#x27;</span>, <span class="string">&#x27;r&#x27;</span>, encoding=<span class="string">&#x27;gbk&#x27;</span>).read()</span><br><span class="line">jieba.analyse.set_stop_words(<span class="string">&#x27;stop_words.txt&#x27;</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 默认提取20个 TF_IDF, withWight返回结果中加上词语的权重</span></span><br><span class="line">keywords_tfidf = jieba.analyse.extract_tags(text, withWeight=<span class="literal">True</span>)</span><br><span class="line"><span class="built_in">print</span>(<span class="string">&quot;TF_IDF&quot;</span>, keywords_tfidf)</span><br><span class="line"></span><br><span class="line"><span class="built_in">print</span>(<span class="string">&#x27;\n&#x27;</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 默认提取20个 Textrank</span></span><br><span class="line">keywords_textrank = jieba.analyse.textrank(text)</span><br><span class="line"><span class="built_in">print</span>(<span class="string">&#x27;Textrank&#x27;</span>, keywords_textrank)</span><br><span class="line"></span><br></pre></td></tr></table></figure><h3 id="文本情感极性分析"><a href="#文本情感极性分析" class="headerlink" title="文本情感极性分析"></a>文本情感极性分析</h3><ul><li>自动情感分类技术<ul><li>字典法 — 遍历所有的情感词，如果是正面情感词则分数为 1，中性词为 0，负面词为 1，将情感分数乘以对应的单词情感程度，计算总和为情感倾向，不同的字典有不同的规则<br><img src="/../%E6%96%87%E6%9C%AC%E5%88%86%E6%9E%90/Untitled%205.png" alt="Untitled"><ul><li>缺点<ol><li>所有词所起的作用性是一样的。当一个褒义的词语和一个贬义的词语一起使用，可能就会使得其情感极性变为中性</li><li>当大段文本中前后出现转折，或者当使用反语或者进行讽刺的时候，就会判断不准确</li></ol></li></ul></li><li>基于机器学习的方法 — 个人理解：神经网络分析文本提取情感特征，类似于 CNN 网络提取图片特征，只不过网络提取特征可能可以有多个指标，一句话，词语等，可以提取或观察到比人类自行定义的指标（字典法）更丰富的特征，所以效果更好<ul><li>使用百度 api</li></ul></li></ul></li></ul><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> jieba</span><br><span class="line"><span class="keyword">import</span> pandas <span class="keyword">as</span> pd</span><br><span class="line"></span><br><span class="line"><span class="built_in">dict</span> = pd.read_excel(<span class="string">&#x27;情感词汇本体.xlsx&#x27;</span>, <span class="number">0</span>)</span><br><span class="line">score = <span class="number">0</span></span><br><span class="line"></span><br><span class="line">text = <span class="string">&#x27;中山大学是伟大的民族英雄、伟大的爱国主义者、中国民主革命的伟大先驱孙中山先生于1924年亲手&#x27;</span>\</span><br><span class="line">    <span class="string">&#x27;创办，中国共产党早期领导人共同创建的大学，是中国传播马克思主义的重要发源地之一，具有优良&#x27;</span>\</span><br><span class="line">    <span class="string">&#x27;革命传统、鲜亮红色基因和卓越品格追求。中山大学起初校名为国立广东大学。孙中山先生逝世后，&#x27;</span>\</span><br><span class="line">    <span class="string">&#x27;学校于1926年定名为国立中山大学。&#x27;</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 设置自定义词典</span></span><br><span class="line">jieba.load_userdict(<span class="string">&#x27;userdict.txt&#x27;</span>)</span><br><span class="line"><span class="comment"># 避免一个专有词语被切割,如果专用词语过多，就采用第一种方法，将所有的专有词语存储在字典之中</span></span><br><span class="line">jieba.suggest_freq(<span class="string">&#x27;国立广东大学&#x27;</span>, <span class="literal">True</span>)</span><br><span class="line">jieba.suggest_freq(<span class="string">&#x27;国立中山大学&#x27;</span>, <span class="literal">True</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 切词，并且在过程中过滤掉停用词</span></span><br><span class="line">segList = jieba.cut(text, use_paddle=<span class="literal">True</span>)</span><br><span class="line"></span><br><span class="line">filteredSegList = []</span><br><span class="line"></span><br><span class="line"><span class="comment"># 将stopwords存储为一个列表</span></span><br><span class="line">stopwords = <span class="built_in">open</span>(<span class="string">&#x27;stop_words.txt&#x27;</span>, encoding=<span class="string">&#x27;UTF-8&#x27;</span>).readlines()</span><br><span class="line"></span><br><span class="line"><span class="keyword">for</span> word <span class="keyword">in</span> segList:</span><br><span class="line">    <span class="keyword">if</span> word+<span class="string">&#x27;\n&#x27;</span> <span class="keyword">not</span> <span class="keyword">in</span> stopwords:</span><br><span class="line">        filteredSegList.append(word)</span><br><span class="line">    <span class="keyword">else</span>:</span><br><span class="line">        <span class="built_in">print</span>(word, end=<span class="string">&#x27; &#x27;</span>)</span><br><span class="line"><span class="built_in">print</span>(<span class="string">&quot;\n切词结果: &quot;</span>, filteredSegList)</span><br><span class="line"></span><br><span class="line"><span class="keyword">for</span> word <span class="keyword">in</span> filteredSegList:</span><br><span class="line">    <span class="keyword">if</span> word <span class="keyword">in</span> <span class="built_in">dict</span>[<span class="string">&#x27;词语&#x27;</span>].tolist():</span><br><span class="line">        word_score = <span class="built_in">dict</span>[<span class="built_in">dict</span>[<span class="string">&#x27;词语&#x27;</span>] == word].iloc[<span class="number">0</span>][<span class="string">&#x27;极性&#x27;</span>]</span><br><span class="line">        <span class="built_in">print</span>(<span class="string">f&#x27;word:<span class="subst">&#123;word&#125;</span>, scores:<span class="subst">&#123;word_score&#125;</span>&#x27;</span>, end=<span class="string">&#x27; &#x27;</span>)</span><br><span class="line">        <span class="keyword">if</span> word_score == <span class="number">1</span>:</span><br><span class="line">            score += <span class="number">1</span></span><br><span class="line">        <span class="keyword">if</span> word_score == <span class="number">2</span>:</span><br><span class="line">            score += -<span class="number">1</span></span><br><span class="line"><span class="built_in">print</span>(<span class="string">f&#x27;\nfinal score: <span class="subst">&#123;score/<span class="built_in">len</span>(filteredSegList)&#125;</span>&#x27;</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 1为褒义 0为中性 -1为贬义</span></span><br><span class="line"><span class="comment"># 计算结果为0.23214 表示情感倾向为中性偏褒</span></span><br><span class="line"></span><br></pre></td></tr></table></figure><h3 id="文本相似度分析"><a href="#文本相似度分析" class="headerlink" title="文本相似度分析"></a>文本相似度分析</h3><ul><li>单词间关系<ul><li>同义关系：两个词可以在任意一个句子中互相替换，且不影响句子所要表达的意思</li><li>反义关系：两个词在对某一个特性的描述的时候是某个尺度上两个相反的极点上的值，往往是对于同一事物或者特性的描述可以在一个句子中互相替换，但会影响句子表达的含义</li><li>上下位关系：一个词比另一个词的含义更加具体</li></ul></li><li>相似度 — 词语的同义关系<ul><li>两个词拥有的相同特征越多，相似度就越大</li></ul></li><li>对比方法<ul><li>基于语义字典的方法:通过两个词在词典层次中的距离来进行计算，不同词性词语之间的相似度难以计算。</li><li>基于分布的方法:从语料中自动提取同义关系和其他词语的关系，通过衡量词语的邻居词分布的相似度，来计算其语义相似性，引入“距离”的概念。 — 一个词语的含义是由周围的词语所共同决定的</li></ul></li><li>常用框架方法<br><img src="/../%E6%96%87%E6%9C%AC%E5%88%86%E6%9E%90/Untitled%206.png" alt="Untitled"></li><li>词袋模型 wordBag<br>将一个文本或文档看做是一袋子单词，不考虑其语法和词序关系每个词都是独立的，然后对这一袋子单词进行编码。<ul><li>缺点<ul><li>词袋模型只计算文档中出现了特定的单词的次数，元素的顺序是任意的，没有考虑词语在文本中的上下文之间的相关信息，损失了语句中单词的顺序特征</li><li>对于每一个语句，无论语句的长短，都会使用相同词典长度的编码每一个单词都具有相同的数值化索引，无法体现单词在文本中重要性</li></ul></li></ul></li><li>word2vec</li></ul><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> gensim <span class="keyword">import</span> downloader</span><br><span class="line"></span><br><span class="line"><span class="comment"># 使用gensim的包文件来计算词语之间的相似度</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">try</span>:</span><br><span class="line">    model = downloader.load(<span class="string">&#x27;word2vec-google-news-300&#x27;</span>)</span><br><span class="line">    <span class="built_in">print</span>(<span class="string">&#x27;car&#x27;</span>, <span class="string">&#x27;minivan&#x27;</span>, model.similarity(<span class="string">&#x27;car&#x27;</span>, <span class="string">&#x27;minivan&#x27;</span>))</span><br><span class="line">    <span class="built_in">print</span>(<span class="string">&#x27;car&#x27;</span>, <span class="string">&#x27;airplane&#x27;</span>, model.similarity(<span class="string">&#x27;car&#x27;</span>, <span class="string">&#x27;airplane&#x27;</span>))</span><br><span class="line"><span class="keyword">except</span> Exception <span class="keyword">as</span> e:</span><br><span class="line">    <span class="built_in">print</span>(<span class="string">&quot;Error loading model:&quot;</span>, <span class="built_in">str</span>(e))</span><br><span class="line"></span><br></pre></td></tr></table></figure><h3 id="主题分析"><a href="#主题分析" class="headerlink" title="主题分析"></a>主题分析</h3><ul><li><p>LDA 模型<br>基于语料库的生成概率模型，将文档表示为潜在主题的随机混合，其中每个主题由一系列单词的分布来表示</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> pyLDAvis.gensim_models</span><br><span class="line"><span class="keyword">from</span> gensim <span class="keyword">import</span> corpora</span><br><span class="line"><span class="keyword">from</span> gensim.models <span class="keyword">import</span> ldamodel</span><br><span class="line"><span class="keyword">import</span> pandas <span class="keyword">as</span> pd</span><br><span class="line"></span><br><span class="line"><span class="comment"># 提取所有词语构成字典</span></span><br><span class="line">contents = pd.read_csv(<span class="string">&#x27;seg_content.csv&#x27;</span>)</span><br><span class="line">texts = []</span><br><span class="line"></span><br><span class="line"><span class="keyword">for</span> content <span class="keyword">in</span> contents[<span class="string">&#x27;content&#x27;</span>]:</span><br><span class="line">    <span class="keyword">if</span> <span class="keyword">not</span> pd.isnull(content):</span><br><span class="line">        texts.append(content.split(<span class="string">&#x27; &#x27;</span>))</span><br><span class="line"></span><br><span class="line">dictionary = corpora.Dictionary(texts)</span><br><span class="line">dictionary.filter_extremes(no_below=<span class="number">2</span>, no_above=<span class="number">0.9</span>)</span><br><span class="line"><span class="built_in">print</span>(<span class="string">&#x27;dictionary&#x27;</span>, <span class="built_in">len</span>(dictionary))</span><br><span class="line"></span><br><span class="line">corpus = [dictionary.doc2bow(text) <span class="keyword">for</span> text <span class="keyword">in</span> texts]</span><br><span class="line"></span><br><span class="line"><span class="keyword">for</span> num_topics <span class="keyword">in</span> <span class="built_in">range</span>(<span class="number">2</span>, <span class="number">10</span>):</span><br><span class="line">    <span class="built_in">print</span>(<span class="string">&#x27;设置主题数量为：&#x27;</span>, num_topics, end=<span class="string">&#x27; &#x27;</span>)</span><br><span class="line">    <span class="comment"># 定义一个LDA模型</span></span><br><span class="line">    lda = ldamodel(corpus=corpus, id2word=dictionary,</span><br><span class="line">                   num_topics=num_topics, passes=<span class="number">60</span>)</span><br><span class="line">    <span class="keyword">for</span> topic <span class="keyword">in</span> lda.print_topics(num_words=<span class="number">10</span>):</span><br><span class="line">        termNumber = topic[<span class="number">0</span>]</span><br><span class="line">        <span class="built_in">print</span>(<span class="string">&#x27;\ntopic&#x27;</span>, topic[<span class="number">0</span>], <span class="string">&#x27;:&#x27;</span>, end=<span class="string">&#x27; &#x27;</span>)</span><br><span class="line">        listOfTerms = topic[<span class="number">1</span>].split(<span class="string">&#x27;+&#x27;</span>)</span><br><span class="line">        <span class="keyword">for</span> term <span class="keyword">in</span> listOfTerms:</span><br><span class="line">            listItems = term.split(<span class="string">&#x27;*&#x27;</span>)</span><br><span class="line">            <span class="built_in">print</span>(<span class="string">&#x27; &#x27;</span>, listItems[<span class="number">1</span>], <span class="string">&#x27;(&#x27;</span>, listItems[<span class="number">0</span>], <span class="string">&#x27;)&#x27;</span>, sep=<span class="string">&#x27;&#x27;</span>, end=<span class="string">&#x27; &#x27;</span>)</span><br></pre></td></tr></table></figure></li></ul>]]></content>
      
      
      
        <tags>
            
            <tag> 自动控制原理 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>PID控制器的设置</title>
      <link href="/2024/05/23/%E5%AE%9E%E9%AA%8C%E6%8A%A5%E5%91%8A/"/>
      <url>/2024/05/23/%E5%AE%9E%E9%AA%8C%E6%8A%A5%E5%91%8A/</url>
      
        <content type="html"><![CDATA[<h2 id="实验问题"><a href="#实验问题" class="headerlink" title="实验问题"></a>实验问题</h2><ol><li>设计一个阀门控制器，实现对蓄水池的蓄水，假设蓄水池的期望蓄水高度是 1 米,当前水位是 0.2 米，列出来基于 Kp&#x3D;0.5 的 P 控制器的蓄水过程。</li></ol><p>2）如果水池下面被司马光同学砸了一个洞，每个 T 时刻，漏水 0.1 米，那么请问，利用你设计的控制器能把水装满吗？为什么？如何改进？对改进后的效果进行一下讨论。</p><h2 id="实验分析和结果"><a href="#实验分析和结果" class="headerlink" title="实验分析和结果"></a>实验分析和结果</h2><ol><li><p>通过 Matlab Simulink 设置控制器如下图，其中 Kp&#x3D;0.5，累加器 1&#x2F;s<br>的初始值设置为 0.2，1&#x2F;z 为延迟单元</p><p><img src="/../PID%E6%8E%A7%E5%88%B6%E5%99%A8%E8%AE%BE%E7%BD%AE/%E5%9B%BE%E7%89%871.png"></p><p>仿真运行结果如下图：蓝色线为水位线随时间变化，橙色线为误差线随时间变化</p><p><img src="/../PID%E6%8E%A7%E5%88%B6%E5%99%A8%E8%AE%BE%E7%BD%AE/%E5%9B%BE%E7%89%872.png"></p></li><li><p>(a) 通过 Matlab Simulink 设置控制器如下图，其中 Kp&#x3D;0.5，累加器 1&#x2F;s<br>的初始值设置为 0.2，同时考虑每个 T 时刻，漏水 0.1 米</p><p><img src="/../PID%E6%8E%A7%E5%88%B6%E5%99%A8%E8%AE%BE%E7%BD%AE/%E5%9B%BE%E7%89%873.png"></p><p>仿真运行结果如下图：蓝色线为水位线随时间变化，橙色线为误差线随时间变化</p><p><img src="/../PID%E6%8E%A7%E5%88%B6%E5%99%A8%E8%AE%BE%E7%BD%AE/%E5%9B%BE%E7%89%874.png"></p><p>由图可得，只使用 P 控制器无法把水装满，最终只能装到 0.8 米处。这是因为水缸中的水位到 0.8 时，则误差 error<br>&#x3D; 1-0.8&#x3D;0.2。<br>所以每次往水缸中加水的量为 u&#x3D;0.5*0.2&#x3D;0.1。同时，每次加水，缸里又会流出去 0.1 米的水，加入的水和流出的水相抵消，水位将不再变化。</p><p>(b)<br>为了消除上述稳态误差，考虑过去误差项，第一次的误差 error 是 0.8，第二次的误差是 0.4，至此，误差的积分 ∫error&#x3D;0.8+0.4&#x3D;1.2.<br>这个时候的控制量，除了比例的那一部分，还有一部分就是一个系数 ki 乘以这个积分项。由于这个积分项会将前面若干次的误差进行累计，所以可以很好的消除稳态误差，使得结果能够达到预期值；通过 Matlab<br>Simulink 设置控制器如下图，将 P 控制器改为 PI 控制器</p><p><img src="/../PID%E6%8E%A7%E5%88%B6%E5%99%A8%E8%AE%BE%E7%BD%AE/%E5%9B%BE%E7%89%875.png"></p><p>从黄色线到蓝色线 Ki 的值分别为 0.2、0.1、0.05,由图观察得，当 Ki 等于 0.05 时，没有超调量，且可以较平稳地收敛到目标值，</p><p><img src="/../PID%E6%8E%A7%E5%88%B6%E5%99%A8%E8%AE%BE%E7%BD%AE/%E5%9B%BE%E7%89%876.png"></p><p>(c) 考虑使用微分控制器，加快响应速度，降低响应时间</p><p><img src="/../PID%E6%8E%A7%E5%88%B6%E5%99%A8%E8%AE%BE%E7%BD%AE/%E5%9B%BE%E7%89%877.png"></p><p><img src="/../PID%E6%8E%A7%E5%88%B6%E5%99%A8%E8%AE%BE%E7%BD%AE/%E5%9B%BE%E7%89%878.png"></p><p>途中蓝色的线是使用 PI 控制器，橙色线使用的是 PID 控制器 Kp &#x3D; 0.5，Ki &#x3D;<br>0.05，Kd &#x3D;<br>0.2，由图可知，使用 PID 控制器的响应时间减少，但是在初始时有一个较大的振荡。但是振荡值在正常范围内。综上，PID 的控制效果最好。</p></li></ol><h2 id="参考资料"><a href="#参考资料" class="headerlink" title="参考资料"></a>参考资料</h2><p><a href="https://zhuanlan.zhihu.com/p/586173469">PID 使用</a></p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br></pre></td><td class="code"><pre><span class="line">import matplotlib.pyplot as plt</span><br><span class="line"></span><br><span class="line">class ApplicationWithKpKiKd:</span><br><span class="line">def __init__(self, ex=1, current=0.2, kp=0.5, ki=0.05, kd=0.1): # 目标值</span><br><span class="line">self.ex = ex # 当前值</span><br><span class="line">self.current = current # 误差值</span><br><span class="line">self.error = self.ex - self.current</span><br><span class="line">self.error_acc = self.error # error accumulation</span><br><span class="line">self.delta_error = self.error # d_e = e(t) - e(t-1) # 设置参数</span><br><span class="line">self.kp = kp</span><br><span class="line">self.ki = ki</span><br><span class="line">self.kd = kd # 迭代次数</span><br><span class="line">self.iterate_times = 0 # 存储结果</span><br><span class="line">self.output_list = [self.current]</span><br><span class="line">self.error_list = [self.error]</span><br><span class="line"></span><br><span class="line">    def run(self):</span><br><span class="line">        self.iterate(100)</span><br><span class="line">        self.plot()</span><br><span class="line">        print(self.output_list)</span><br><span class="line">        print(&quot;[info] iterate times: &quot;, self.iterate_times)</span><br><span class="line"></span><br><span class="line">    def iterate(self, epoch):</span><br><span class="line">        &quot;&quot;&quot; iterate to update current, error &quot;&quot;&quot;</span><br><span class="line">        for i in range(epoch):</span><br><span class="line">            # 加水量u</span><br><span class="line">            u = self.kp * self.error + self.ki * self.error_acc</span><br><span class="line">            self.current += u - 0.1</span><br><span class="line"></span><br><span class="line">            self.error = self.ex - self.current</span><br><span class="line">            self.error_acc += self.error</span><br><span class="line">            self.delta_error = self.error - self.error_list[-1]</span><br><span class="line"></span><br><span class="line">            self.output_list.append(self.current)</span><br><span class="line">            self.error_list.append(self.error)</span><br><span class="line">            self.iterate_times = epoch</span><br><span class="line"></span><br><span class="line">    def plot(self):</span><br><span class="line">        l1, = plt.plot(list(range(len(self.output_list))),</span><br><span class="line">                       self.output_list, label=&#x27;output&#x27;)</span><br><span class="line">        l2, = plt.plot(list(range(len(self.error_list))),</span><br><span class="line">                       self.error_list, label=&#x27;error&#x27;, linestyle=&#x27;--&#x27;, color=&#x27;r&#x27;)</span><br><span class="line">        l3 = plt.plot(list(range(len(self.output_list))), [</span><br><span class="line">                      1] * len(self.output_list), linestyle=&#x27;--&#x27;, color=&#x27;g&#x27;)</span><br><span class="line">        plt.xlabel(&#x27;times / s&#x27;)</span><br><span class="line">        plt.ylabel(&#x27;water volume / (m^3)&#x27;)</span><br><span class="line">        plt.legend(handles=[l1, l2],</span><br><span class="line">                   labels=[&#x27;output&#x27;, &#x27;error&#x27;])</span><br><span class="line">        plt.show()</span><br><span class="line"></span><br><span class="line">if __name__ == &#x27;__main__&#x27;:</span><br><span class="line">app = ApplicationWithKpKiKd(kp=0.5, ki=0.05, kd=0.1)</span><br><span class="line">app.run()</span><br></pre></td></tr></table></figure>]]></content>
      
      
      
        <tags>
            
            <tag> 自动控制原理 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Games of GANs</title>
      <link href="/2024/05/21/Games-of-GANs/"/>
      <url>/2024/05/21/Games-of-GANs/</url>
      
        <content type="html"><![CDATA[<blockquote><p>博弈论期中课程论文撰写: 要求研读至少一篇的有关博弈论想过论文，并写一份报告</p></blockquote><h3 id="研究背景"><a href="#研究背景" class="headerlink" title="研究背景"></a>研究背景</h3><p>生成对抗网络(GANs)是一类生成类模型，首先由 Goodfellow et al.(2014b)提出，该模型因其对高纬度复杂现实数据进行建模的潜力和可以从潜在的空间中生成无限真实的新样本的能力而广泛应用于各个领域，从文本编辑图像、图像合成到计算机视觉、视频再到动画生成和网络安全(Alqahtani et al. 2021)而广受关注。GANs 的核心思想受到零和极大极小博弈的启发，零和极大极小博弈是指一方的收益必然意味着另一方的损失博弈各方的收益和损失相加总和永远为“零”，同时决策者最大化最坏情况下的收益。在 GANs 的框架下有两个模型，一个是判别器，一个是生成器，生成器生成接近于真实数据的分布，让判别器无法判别真实数据和生成数据，而判别器则是识别出生成器生成的数据，直到 GANs 模型达到纳什均衡，在该均衡下，判别器和生成器都无法在不减少对<br>方增益的情况下增加自己的增益。GANs 自从推出以来，受到了广泛的研究，然而 GANs 模型有难以训练，不稳定的问题，例如：模式坍塌、无法收敛和梯度消失等问题(Wang et al. 2019)。GANs 在训练过程中需要收敛到纳什均衡，但这种收敛被证明非常具有挑战性(Wiatrak and Albert 2019)。为了提高 GANs 的能力，改进和完善 GANs 的缺点，有必要从基础原理出发即博弈论的角度去改善 GANs 的性能，但从博弈论视角出发去研究改善 GANs 的研究不多，故该研究有助于丰富 GANs 的研究视角。</p><h3 id="研究方法"><a href="#研究方法" class="headerlink" title="研究方法"></a>研究方法</h3><p>博弈论的三个基本要素为玩家(players)、策略(strategy)、收益(playoff)，改变其中任何一个要素都会影响博弈的进程和结果；因此有许多论文通过改变以上三个要素的一个或多个来实现优化和改进 GANs。</p><ol><li><p><strong>改变博弈模型</strong><br>一些论文认为 GANs 难以训练和收敛是因为传统 GANs 被视作零和极大极小博弈，想要达到纳什均衡非常困难，因此(FA Oliehoek. 2017)将零和极大极小博弈视为有限零和博弈，并根据有限零和博弈的特性：在混合策略的空间中，任何局部纳什均衡都是全局纳什均衡来避免模型陷入局部最优，同时提出资源有限纳什均衡的概念来解决运算量过大和难以收敛的问题。.Farnia et al. in Farnia and Ozdaglar (2020)则认为，先训练判别器，再训练生成器的模式可以被视作斯塔克尔博弈(Stackelberg game)，转而让模型关注到子博弈纳什均衡。</p></li><li><p><strong>改变玩家数量</strong><br>由于 GAN 的训练需要两个模型的共同参与，一旦有任何一个生成器(player)训练失败，就会降低整体的训练效果，即如果判别器判别能力很差，那么生成器就无法根据较好的反馈，生成接近真实数据的分布。根据(Zhanget al. 2018c)提出的具有多生成器架构的 GAN 的极大极小值差距更小，训练性能更加稳定这一论点，许多文章提出了不同的解决方案。</p><h5 id="a-一个生成器多个判别器"><a href="#a-一个生成器多个判别器" class="headerlink" title="(a) 一个生成器多个判别器"></a>(a) 一个生成器多个判别器</h5><p>训练一个过好的判别器会损坏生成器的性能，这是 GAN 面临的一个大难题，如果能够训练多个判别能力没有那么强的判别器，可以提升生<br>成器的性能，并且多个判别器可以相互进行分工，关注图像的不同特征。</p><h5 id="b-一个判别器多个生成器"><a href="#b-一个判别器多个生成器" class="headerlink" title="(b) 一个判别器多个生成器"></a>(b) 一个判别器多个生成器</h5><p>一般来说，生成器相比判别器要完成的任务更难，因为它要完成数据概率密度的拟合，而判别器只需要进行判别，一个判别器一个生成器架构容易产生的一个问题便是“模式坍塌”即生成器由于发现了判别器的盲点，所以为了获得更高的分数就一直生成高度相似的图片，因此多个判别器能够一定程度上防止生成器找到某一个漏洞而持续生成高度相似的图片，能够有效地缓解模式坍塌这个问题。</p></li><li><p><strong>改变学习策略的方法</strong></p><h5 id="a-无悔学习算法-No-regret-learning"><a href="#a-无悔学习算法-No-regret-learning" class="headerlink" title="(a) 无悔学习算法(No-regret learning)"></a>(a) 无悔学习算法(No-regret learning)</h5><p>一般来讲，采用基于后悔值的学习方法以后，每个智能体根据各个行为的后悔值做出行为选择。如果一种算法能够保证最大后悔值渐进的变<br>为零，那么该种算法就可以被称作无悔学习算法。 Grnarova et al.(2017)采用了无悔最小化方法，他们提供了一种可以证明收敛到 MN 均衡的方法。因为生成者纯策略的最小值总是高于生成者混合均衡策略的最小值</p><h5 id="b-虚拟博弈-Fictitious-Play"><a href="#b-虚拟博弈-Fictitious-Play" class="headerlink" title="(b) 虚拟博弈(Fictitious Play)"></a>(b) 虚拟博弈(Fictitious Play)</h5><p>虚拟博弈常被用来解决零和博弈问题，其基本思想是：使每个智能体拥有两个策略集。一个是最优策略集，一个是历史平均策略集。在每一轮博弈的开始，每个均智能体根据对手的历史平均策略集，找到一个最优的针对策略。然后根据历史平均策略和本轮最优策略更新自己的历史平均策略。Ge at al.（2018）设计了一种训练算法来模拟 GAN 上的虚构游戏，并提供了理论上的收敛保证。他们还表明，通过在虚构 GAN 中每次更新时假设最佳响应，生成器的混合输出分布会收敛到数据分布。判别器输出收敛于最佳判别器函数。Ge at al.（2018）中的作者使用两个队列 D 和 G 来存储判别器和生成器的历史训练模型。他们还表明，虚构 GAN 可以有效解决标准训练方法无法解决的一些收敛问题，并可应用于现有的 GAN 变体之上。</p></li></ol><h3 id="结论"><a href="#结论" class="headerlink" title="结论"></a>结论</h3><p>该研究从 GAN 的原理出发，论述了 GAN 的原理、应用和训练上遇到的种种问题如：难以收敛、模式坍塌等，文章认为想要更好的改善这些问题，需要从 GAN 的原理出发，即零和极大极小博弈，从博弈论的三个核心要素：玩家(players)、策略(strategy)、收益(playoff)上出发对 GAN 的改进和优化。</p><h3 id="参考文献"><a href="#参考文献" class="headerlink" title="参考文献"></a>参考文献</h3><ol><li>Goodfellow, I., Pouget-Abadie, J., Mirza, M., Xu, B., Warde-Farley, D., Ozair, S., … &amp; Bengio,<br>Y. (2014). Generative adversarial nets. Advances in neural information processing<br>systems, 27.</li><li>Alqahtani, H., Kavakli-Thorne, M., &amp; Kumar, G. (2021). Applications of generative<br>adversarial networks (gans): An updated review. Archives of Computational Methods in<br>Engineering, 28, 525-552.</li><li>Wang, Z., She, Q., &amp; Ward, T. E. (2021). Generative adversarial networks in computer<br>vision: A survey and taxonomy. ACM Computing Surveys (CSUR), 54(2), 1-38.</li><li>Wiatrak, M., Albrecht, S. V., &amp; Nystrom, A. (2019). Stabilizing generative adversarial<br>networks: A survey. arXiv preprint arXiv:1910.00927.</li><li>Oliehoek, F. A., Savani, R., Gallego-Posada, J., Van der Pol, E., De Jong, E. D., &amp; Groß,<br>R. (2017). GANGs: Generative adversarial network games. arXiv preprint<br>arXiv:1712.00679.</li><li>Farnia, F., &amp; Ozdaglar, A. (2020). Gans may have no nash equilibria. arXiv preprint<br>arXiv:2002.09124.</li><li>Zhang, H., Xu, S., Jiao, J., Xie, P., Salakhutdinov, R., &amp; Xing, E. P. (2018). Stackelberg<br>GAN: Towards provable minimax equilibrium via multi-generator architectures. arXiv<br>preprint arXiv:1811.08010.</li><li>Grnarova, P., Levy, K. Y., Lucchi, A., Hofmann, T., &amp; Krause, A. (2017). An online learning<br>approach to generative adversarial networks. arXiv preprint arXiv:1706.03269.</li></ol>]]></content>
      
      
      
        <tags>
            
            <tag> 博弈论课程 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>GAN</title>
      <link href="/2024/05/21/GAN/"/>
      <url>/2024/05/21/GAN/</url>
      
        <content type="html"><![CDATA[<h3 id="Network-as-Generator"><a href="#Network-as-Generator" class="headerlink" title="Network as Generator"></a>Network as Generator</h3><p>输入新增加一个 Z，Z 来源(sample)于一个简单的 distribution，通过神经网络的转化之后输出一个复杂的 distribution，那么这个 network 就被称为<strong>generator</strong><br><img src="/../GAN_imgs/Untitled.png" alt="Untitled"></p><blockquote><p>❓ 那为什么要生成一个分布呢？</p></blockquote><ol><li>让神经网络的输出不再是一个<strong>单一</strong>的输出，而是输出一个概率分布，这个分布包含了很多的可能性，解决这个世界有很多不可预测确定值的问题</li><li>需要一个 function，同样的输入有很多不同的输出 → 让机器具有创造力（draw，chatbot）</li></ol><h3 id="Generative-Adversarial-Network-GAN"><a href="#Generative-Adversarial-Network-GAN" class="headerlink" title="Generative Adversarial Network(GAN)"></a>Generative Adversarial Network(GAN)</h3><blockquote><p>🦁 <a href="https://github.com/hindupuravinash/the-gan-zoo">https://github.com/hindupuravinash/the-gan-zoo</a> - gan 的动物园</p></blockquote><ul><li><p>Anime Face Generator</p><ol><li>没有 x 输入，只输入 z</li><li>simple distribution 的选择产生的差异不是很大<br><img src="/../GAN_imgs/Untitled%201.png" alt="Untitled"></li></ol></li><li><p>Anime Face Discriminator</p><ol><li>因为输入的是一张图片，所以大概率会选择 CNN<br><img src="/../GAN_imgs/Untitled%202.png" alt="Untitled"></li></ol></li><li><p>Basic Idea of GAN<br>GANs 的核心思想受到零和极大极小博弈的启发，零和极大极小博弈是指一方的收益必然意味着另一方的损失博弈各方的收益和损失相加总和永远为“零”，同时决策者最大化最坏情况下的收益。在 GANs 的框架下有两个模型，一个是判别器，一个是生成器，生成器生成接近于真实数据的分布，让判别器无法判别真实数据和生成数据，而判别器则是识别出生成器生成的数据，直到 GANs 模型达到纳什均衡，在该均衡下，判别器和生成器都无法在不减少对方增益的情况下增加自己的增益。</p><ul><li>Anime Face Generator vs Anime Face Discriminator<br><img src="/../GAN_imgs/Untitled%203.png" alt="Untitled"></li></ul></li><li><p>Algorithm</p><ol><li><p>Initialize generator and discriminator</p></li><li><p>In each training iteration</p><ol><li><strong>step1:</strong> Fix generator G, and update discriminator D<ul><li>Discriminator learns to assign high scores to real objects and low scores to generated objects. - 可以当作分类问题也可以当作回归问题</li></ul></li><li><strong>step2:</strong> Fix discriminator D and update generator G<ul><li>训练的目标是让 discriminator 打的分越高越好，generator learns to “fool” the discriminator<br><img src="/../GAN_imgs/Untitled%204.png" alt="Untitled"></li></ul></li></ol></li></ol><blockquote><p>💡 训练一阵子 genrator，训练一阵子 discriminator</p></blockquote></li></ul><h3 id="Theory-behind-GAN"><a href="#Theory-behind-GAN" class="headerlink" title="Theory behind GAN"></a>Theory behind GAN</h3><ul><li><p>训练目标</p><ul><li><p>生成器(generator)的目标</p><ul><li>真实数据的分布和生成器生成的数据分布越接近越好<br>在 generator 中 loss function 就是 divergence(P_G, P_data)<br><img src="/../GAN_imgs/Untitled%205.png" alt="Untitled"></li><li>但是如何计算 divergence？ — 无法计算，需要找别的方法<br>采用<strong>Sample</strong>的方法<br><img src="/../GAN_imgs/Untitled%206.png" alt="Untitled"></li></ul></li><li><p>判别器(discriminator)的目标<br><img src="/../GAN_imgs/Untitled%207.png" alt="Untitled"><br>等同于训练一个<strong>Classifier</strong></p><blockquote><p>💡 discriminator 计算出来的 argmaxV(D,G)的值和 divergence 是相关的，即 maxV(D,G)的值越小，则说明真实数据和生成数据非常接近，因此 discriminator 的目标函数也可以作为评价 generator 的指标</p></blockquote><p><img src="/../GAN_imgs/Untitled%208.png" alt="Untitled"></p></li></ul></li><li><p>GAN is difficult to train — <strong>tips</strong> to train GAN</p><ul><li>JS divergence is not suitable<br><img src="/../GAN_imgs/Untitled%209.png" alt="Untitled"><ul><li>对于两个没有重叠的分布对 js divergence 有什么影响<br>尽管 P_G 和 P_data 越来越接近，但是如果使用二分类的 discriminator 无法提供任何信息<br><img src="/../GAN_imgs/Untitled%2010.png" alt="Untitled"></li></ul></li><li>Wasserstein distance — 用于处理先前 JS divergence 的问题<ul><li>可以反映出 generator 是否比先前更好<br><img src="/../GAN_imgs/Untitled%2011.png" alt="Untitled"></li><li>WGAN<ul><li>D 采样的值必须要平滑，不能够变化剧烈，要不然如果值很大，但是每次只变化一点，那就没法判断 generator 是否变好，就会变成和 JS divergence 一样的问题<br><img src="/../GAN_imgs/Untitled%2012.png" alt="Untitled"></li><li>那么满足足够平滑这个条件呢？<ul><li>Gradient Penalty</li><li>Spectral Normalization</li></ul></li></ul></li></ul></li></ul></li></ul><h3 id="GAN-is-still-challenging-—-difficult-to-train"><a href="#GAN-is-still-challenging-—-difficult-to-train" class="headerlink" title="GAN is still challenging — difficult to train"></a>GAN is still challenging — difficult to train</h3><blockquote><p>❓ 用 GAN 生成一段文字是最困难的</p></blockquote><blockquote><p>❓ 无法使用 gradient descent 的模型可以考虑使用 reinforcment training</p></blockquote><h3 id="Evalution-of-GAN"><a href="#Evalution-of-GAN" class="headerlink" title="Evalution of GAN"></a>Evalution of GAN</h3><ul><li>Human evaluation is expensive (and sometimes unfair&#x2F;unstable) <strong>??</strong></li><li>How to evaluate the quality of the generated images automatically <strong>??</strong></li><li>Mode Collapse(模式坍塌)<ul><li>generate 总是生成相同的图片，因为发现可能这个图片是 discriminator 的盲点，所以为了获得更高的分数就一直生成这些图片<br><img src="/../GAN_imgs/Untitled%2013.png" alt="Untitled"></li><li>今天还没有一个非常好的办法解决 mode collapse</li></ul></li><li>Diversity - Mode Dropping<br><img src="/../GAN_imgs/Untitled%2014.png" alt="Untitled"></li><li>使用影像分类器 — Good quality<br>输出的分布越集中，说明效果越好<br><img src="/../GAN_imgs/Untitled%2015.png" alt="Untitled"></li><li>如何检测多样性 — large diversity<ul><li>每一张图片丢到图像分类器都识别出 class2<br><img src="/../GAN_imgs/Untitled%2016.png" alt="Untitled"></li><li>丢不同的图片的时候识别的 class 都不太一样，说明是具备 diversity<br><img src="/../GAN_imgs/Untitled%2017.png" alt="Untitled"></li></ul></li></ul><blockquote><p>💡 Good quality 是根据一张图片，large diversity 是根据很多张图片取平均 （IS）</p></blockquote><ul><li><p>FID — Frechet Inception Distance</p><ul><li>计算距离比较相似度 — samller is better<br><img src="/../GAN_imgs/Untitled%2018.png" alt="Untitled"></li></ul></li><li><p>加入产生的图片和训练资料的图片一模一样 —&gt; Memory GAN<br><img src="/../GAN_imgs/Untitled%2019.png" alt="Untitled"></p><blockquote><p>💡 因此评估 GAN 非常困难</p></blockquote></li><li><p>Condition Generator</p><ul><li>作用 — Text-to-image — supervise learning<br><img src="/../GAN_imgs/Untitled%2020.png" alt="Untitled"><ul><li>discriminator 要同时接受图片和文本，只有图片和文本是相配的，才能拿高分；但是一般这样训练出来的结果不够好<br><img src="/../GAN_imgs/Untitled%2021.png" alt="Untitled"></li><li>为了改进上述的问题，需要加入负样本<br><img src="/../GAN_imgs/Untitled%2022.png" alt="Untitled"></li></ul></li><li>图片的风格转化 — image translation<br><img src="/../GAN_imgs/Untitled%2023.png" alt="Untitled"></li></ul></li></ul><h3 id="Learning-from-Unpair-Data"><a href="#Learning-from-Unpair-Data" class="headerlink" title="Learning from Unpair Data"></a>Learning from Unpair Data</h3><blockquote><p>💡 把 GANs 运用到 unsupurised learning</p></blockquote><ul><li><p>使用未标注，不成对的数据</p><ol><li><p>有一部分资料是成对的</p><p>pseudo labeling、back translation</p></li><li><p>完全没有成对的资料 - 影像风格转化</p><p><img src="/../GAN_imgs/Untitled%2024.png" alt="Untitled"></p></li></ol></li><li><p>如何使用 GANs<br>用 network 将 domain x 的东西转化为 domain y<br><img src="/../GAN_imgs/Untitled%2025.png" alt="Untitled"></p></li><li><p>Cycle GAN<br>discriminator 判断图片是否属于 y domain，但是仅仅判断是否属于 y domain 还不够，需要输入与输出有关系，考虑使用 conditional GAN，但是也没有办法直接套用 conditional GAN，因为没有成对的资料<br><img src="/../GAN_imgs/Untitled%2026.png" alt="Untitled"><br>使用两个 generator，一个 generator 将 x domain 转化为 y domain，另一个 generator 将 y domain 转化为 x domain，然后比较两个图片的距离，越接近越好。加入 cycle，可以保证 y domain 的输出与 x domain 输入有关<br><img src="/../GAN_imgs/Untitled%2027.png" alt="Untitled"><br>双向的 cycle GAN<br><img src="/../GAN_imgs/Untitled%2028.png" alt="Untitled"></p></li></ul>]]></content>
      
      
      
        <tags>
            
            <tag> 李宏毅机器学习 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>CNN</title>
      <link href="/2024/05/14/CNN/"/>
      <url>/2024/05/14/CNN/</url>
      
        <content type="html"><![CDATA[<h3 id="Neuron-Version-Story"><a href="#Neuron-Version-Story" class="headerlink" title="Neuron Version Story"></a>Neuron Version Story</h3><ul><li>一张图片是 3 维的 tensor，(channel, height, weight)。channel 表示 rgb 三通道；将图片的三维压缩成一维度向量输入到神经网络<br><img src="/../CNN_img/Untitled.png" alt="Untitled"></li><li>如果使用<strong>Fully Connected Network</strong>，需要的参数量非常巨大，输入向量长度为 100 X 100 X 3， 神经元个数是 1000 个，模型参数越多，越容易 overfiting</li><li>Observation1<ul><li>神经元的作用：Identifying some critical patterns，发现一些重要的特征<br><img src="/../CNN_img/Untitled%201.png" alt="Untitled"></li><li>Some patterns are much smaller than the whole image.特征只占图片的一小部分<ol><li>每一个 neural 只关注一小部分（receptive field）就好了</li><li>receptive field 可以重叠</li><li>receptive field 可以只 cover 部分 channel</li><li>receptive field 不一定要是正方形<br><img src="/../CNN_img/Untitled%202.png" alt="Untitled"><br><img src="/../CNN_img/Untitled%203.png" alt="Untitled"></li></ol></li><li>Typical Setting<ol><li>考虑所有的 channel</li><li>receptive field 也被称为 kernel size，一般设置为 3*3</li><li>同一个 receptive field 会有一组，一排去检测它（64 个神经元）</li><li>stride 表示每个 receptive field 之间的间隔是多少 （stride &#x3D; 2），最好每个 receptive field 之间有一定的重叠</li><li>receptive field 有一部分超出了图片的范围，那么就用 padding 来补充<br><img src="/../CNN_img/Untitled%204.png" alt="Untitled"></li></ol></li></ul></li><li>Observation2:<ul><li>The same patterns appear in different regions<ul><li>每一个 receptive field 都有一个侦测鸟嘴的神经元 → 问题：参数量太多了<br><img src="/../CNN_img/Untitled%205.png" alt="Untitled"></li><li>解决方案：<strong>参数共享</strong>，虽然参数一样，但是输入是不一样的，所以输出是不一样的<br><img src="/../CNN_img/Untitled%206.png" alt="Untitled"></li><li>Typical Setting - 常见的共享参数的方法<br><img src="/../CNN_img/Untitled%207.png" alt="Untitled"></li></ul></li></ul></li></ul><h3 id="Convolution-Layer-—-another-story-based-on-filter"><a href="#Convolution-Layer-—-another-story-based-on-filter" class="headerlink" title="Convolution Layer — another story based on filter"></a>Convolution Layer — another story based on filter</h3><ol><li>从图片中去抓取 pattern</li></ol><ul><li>计算方式<br><img src="/../CNN_img/Untitled%208.png" alt="表明左上角和左下角都出现了这个pattern"><br>表明左上角和左下角都出现了这个 pattern</li><li>future map<br>如果有 64 个 filter，那么就会有 64<em>4</em>4 的矩阵，可以把这个 future map 理解成一张新的图片，有 64 个 channel<br><img src="/../CNN_img/Untitled%209.png" alt="Untitled"></li></ul><ol><li>如果 network 足够深，filter 能够看到足够大的 pattern</li></ol><ul><li><strong>Observation3</strong><ol><li>Subsampling the pixels will not change the object - 放大缩小(减去行和列的条数)图片不会对图像内容造成影响</li></ol><ul><li>Pooling - Max Pooling<ul><li>Pooling 的作用 - 减少运算量，如果运算量足够强，也可以不做 pooling<br><img src="/../CNN_img/Untitled%2010.png" alt="Untitled"></li><li>Convolutional Layers + Pooling<br><img src="/../CNN_img/Untitled%2011.png" alt="Untitled"></li></ul></li></ul></li></ul><h3 id="The-whole-CNN"><a href="#The-whole-CNN" class="headerlink" title="The whole CNN"></a>The whole CNN</h3><p><img src="/../CNN_img/Untitled%2012.png" alt="Untitled"></p><p><img src="/../CNN_img/Untitled%2013.png" alt="Untitled"></p><blockquote><p>❓ CNN 无法处理放大和缩小之后或旋转的图像，CNN is not invariant to scaling and rotation</p></blockquote><blockquote><p>💡 通过影像的特性来对模型进行限制，避免 overfitting</p></blockquote><h3 id="改善-CNN-的方法"><a href="#改善-CNN-的方法" class="headerlink" title="改善 CNN 的方法"></a>改善 CNN 的方法</h3><p>→ need data augmentation — 处理旋转问题</p><p>→ 处理放大缩小问题 — Spatial Transformer Layer</p>]]></content>
      
      
      
        <tags>
            
            <tag> 李宏毅机器学习 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Framework of ML</title>
      <link href="/2024/05/14/Framework%20of%20ML%208c9833550a9e4691b4fe4a8532ac1d84/"/>
      <url>/2024/05/14/Framework%20of%20ML%208c9833550a9e4691b4fe4a8532ac1d84/</url>
      
        <content type="html"><![CDATA[<ul><li><p>训练过程<br><img src="/../Framework_of_ml/Untitled.png" alt="Untitled"></p></li><li><p>训练方法—如何调整神经网络让效果更好<br><img src="/../Framework_of_ml/Untitled%201.png" alt="Untitled"></p><ul><li><p>首先检查 training data loss：判断在训练资料是否学好了</p><ol><li><p>如果没有学好：可以考虑<strong>model bias</strong></p><ul><li><p>model bias</p><ul><li><p>the model is too simple</p><blockquote><p>💡 solution: redesign your model to make it more flexible，重新设计模型</p></blockquote><p><img src="/../Framework_of_ml/Untitled%202.png" alt="Untitled"></p></li></ul></li></ul></li><li><p>也可能是<strong>optimization issue</strong>，陷入到局部最优之中</p></li><li><p>如何判断是 model bias 的问题，即模型不够大，还是 optimization 选取的不够好？通过比较判断</p><p><img src="/../Framework_of_ml/Untitled%203.png" alt="Untitled"></p><blockquote><p>💡 56 层网络的表达能力更强，肯定可以选出合适的 function，得到和 20 层一样低的 loss，所以这里是 optimization 的 issue</p></blockquote><ul><li>Gaining the insights from comparison</li><li>Start from shallower networks(or other models), which are eaiser to optimization</li><li>if deeper networks do not obtain smaller loss on training data, then there is optimization issue<br><img src="/../Framework_of_ml/Untitled%204.png" alt="Untitled"></li></ul></li></ol></li><li><p>如果<strong>training data loss</strong>足够小了，则可以来判断<strong>testing data loss</strong></p><ol><li>如果小就结束了</li></ol><ul><li><p>如果在<strong>testing data loss</strong>很大的话，就可以考虑 overfitting<br><img src="/../Framework_of_ml/Untitled%205.png" alt="Untitled"><br><img src="/../Framework_of_ml/Untitled%206.png" alt="Untitled"></p><blockquote><p>❓ 比较有弹性的 model 跟家容易 overfitting</p></blockquote><ul><li><p>如何解决 overfitting</p><ul><li><p>增加训练资料<br><img src="/../Framework_of_ml/Untitled%207.png" alt="Untitled"></p></li><li><p>data augmentation-根据自己对数据的理解，增加新的训练数据，要 augment 的有道理<br><img src="/../Framework_of_ml/Untitled%208.png" alt="Untitled"><br>上下翻转的猫猫不会出现在现实世界里</p></li><li><p>增加限制 - 正则化 - 也取决与对 model 的理解<br><img src="/../Framework_of_ml/Untitled%209.png" alt="Untitled"></p><blockquote><p>💡 Less Parameters, sharing parameters, early stopping, regularization, dropout</p></blockquote></li><li><p>限制也不能太大<br><img src="/../Framework_of_ml/Untitled%2010.png" alt="Untitled"><br>限制过多又会导致模型弹性不够的问题</p></li><li><p>Bias-Complexity Trade-off<br><img src="/../Framework_of_ml/Untitled%2011.png" alt="Untitled"></p></li></ul></li></ul></li><li><p>除此之外还可以考虑 mismatch</p><ul><li>Your training and testing data have <strong>different distributions</strong></li></ul></li></ul></li></ul></li><li><p>判断模型好坏的方法—cross validation<br><img src="/../Framework_of_ml/Untitled%2012.png" alt="Untitled"><br><img src="/../Framework_of_ml/Untitled%2013.png" alt="Untitled"></p></li></ul>]]></content>
      
      
      
        <tags>
            
            <tag> 李宏毅机器学习 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Optimization</title>
      <link href="/2024/05/14/Optimization/"/>
      <url>/2024/05/14/Optimization/</url>
      
        <content type="html"><![CDATA[<h3 id="Optimization："><a href="#Optimization：" class="headerlink" title="Optimization："></a>Optimization：</h3><ul><li>What is Optimization about<ul><li>找到一个神经网络的参数，让 y_hat 和 y 很接近，也就是让 loss 最小</li><li>on-line learning: 每一个 time step 只能看到当前的 x_t</li><li>off-line learning： 一次可以拿到所有的训练资料</li></ul></li><li>SGD<br><img src="/../Optimization/Untitled.png" alt="Untitled"></li><li>SGD with Momentum(SGDM)<br><img src="/../Optimization/Untitled%201.png" alt="Untitled"><br><img src="/../Optimization/Untitled%202.png" alt="Untitled"></li><li>Adagrad<ul><li>如果过去的 gradient 很大，说明当前的下降的路比较陡，那么分母就会比较大，那么每次走的步数比较小<br><img src="/../Optimization/Untitled%203.png" alt="Untitled"></li></ul></li><li>RMSProp<ul><li>解决 Adagrad 的问题，如果初始的 gradient 就特别大，那么就会导致 learning rate 非常的小，很有可能就卡着不动了，所以这里除以的分母是一个和时间相关联的量<br><img src="/../Optimization/Untitled%204.png" alt="Untitled"></li></ul></li><li>Adam<br><img src="/../Optimization/Untitled%205.png" alt="Untitled"></li></ul><h3 id="Application"><a href="#Application" class="headerlink" title="Application"></a>Application</h3><ul><li>Adam vs SGDM<br><img src="/../Optimization/Untitled%206.png" alt="Untitled"></li><li>Simple combine Adam with SGDM → SWATS<br><img src="/../Optimization/Untitled%207.png" alt="Untitled"></li></ul>]]></content>
      
      
      
        <tags>
            
            <tag> 李宏毅机器学习 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Saddle Point and Local Minima</title>
      <link href="/2024/05/14/Saddle%20Point%20and%20Local%20minima/"/>
      <url>/2024/05/14/Saddle%20Point%20and%20Local%20minima/</url>
      
        <content type="html"><![CDATA[<ul><li><p>Optimization Fails beacause</p><ul><li>local minima（no way to go） 和 saddle point （can escape）统称为 critical point<br><img src="/../Saddlepoint/Untitled.png" alt="Untitled"></li></ul></li><li><p>如何判断是 local minima 还是 saddle point</p><ul><li><p>Tayler Series Approximation - 通过泰勒近似，求出损失函数的近似，gradient 为一次积分，hessian 为二次积分<br><img src="/../Saddlepoint/Untitled%201.png" alt="Untitled"></p></li><li><p>因为 local minima 和 saddle 都是 gradient 为 0 的点，所以通过 Hessian 来判断<br><img src="/../Saddlepoint/Untitled%202.png" alt="Untitled"></p></li><li><p>一个例子：data 为输入 1，输出为 1<br><img src="/../Saddlepoint/Untitled%203.png" alt="Untitled"></p></li><li><p>如果是一个 saddle point 的时候，H 可以告诉我们 Parameter update direction<br><img src="/../Saddlepoint/Untitled%204.png" alt="Untitled"><br><img src="/../Saddlepoint/Untitled%205.png" alt="Untitled"></p><blockquote><p>💡 一般不会去算 Hessian, 还有其他方法，因为计算 Hessian 的计算量要求很大</p></blockquote></li></ul></li><li><p>Saddle Point vs Local Minima</p><blockquote><p>💡 也许当前碰到的 local minima 或 saddle point 只是在当前维度下，也许升高维度就会有路可以走</p></blockquote></li></ul>]]></content>
      
      
      
        <tags>
            
            <tag> 李宏毅机器学习 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>使用 google-colab 云端训练</title>
      <link href="/2024/05/12/%E4%BD%BF%E7%94%A8google-colab/"/>
      <url>/2024/05/12/%E4%BD%BF%E7%94%A8google-colab/</url>
      
        <content type="html"><![CDATA[<ol><li>将代码和数据集压缩载入到 google colab，上传完毕后解压</li></ol><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">!unzip /content/yolo.<span class="built_in">zip</span> -d /content/yolov5</span><br></pre></td></tr></table></figure><ol><li>需要删除文件_MACOSX(一些关于操作系统的配置)</li></ol><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">!rm -rf /content/_MACOSX</span><br></pre></td></tr></table></figure><ol><li>进入到代码目录</li></ol><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">%cd /content/yolov5/yolov5-<span class="number">5.0</span></span><br></pre></td></tr></table></figure><ol><li>安装依赖包文件</li></ol><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">!pip install -r requirements.txt</span><br></pre></td></tr></table></figure><ol><li>启动 tensorboard</li></ol><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">%load_ext tensorboard</span><br><span class="line"><span class="comment"># 如果想要重新加载就使用reload_ext</span></span><br><span class="line"></span><br><span class="line">%tensorboard --logdir=runs/train</span><br></pre></td></tr></table></figure><ol><li>运行 train.py 文件</li></ol><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">!python train.py --rect</span><br></pre></td></tr></table></figure>]]></content>
      
      
      
        <tags>
            
            <tag> 深度学习 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>形式与政策</title>
      <link href="/2024/05/05/%E5%BD%A2%E5%BC%8F%E4%B8%8E%E6%94%BF%E7%AD%96/"/>
      <url>/2024/05/05/%E5%BD%A2%E5%BC%8F%E4%B8%8E%E6%94%BF%E7%AD%96/</url>
      
        <content type="html"><![CDATA[<p>💀 一直对学校中形式主义的教学和任务深恶痛绝，为减轻他人负担，故分享 <strong>此文章由 GPT4 生成，可随性引用</strong></p><h1 id="琢磨全球风云：新时代大学生的国际视野与责任担当"><a href="#琢磨全球风云：新时代大学生的国际视野与责任担当" class="headerlink" title="琢磨全球风云：新时代大学生的国际视野与责任担当"></a>琢磨全球风云：新时代大学生的国际视野与责任担当</h1><p>作为新时代大学生，“风声雨声读书声，声声入耳；家事国事天下事，事事关心”是对我们最基本的要求。而《形式与政策》这门课程给了我一个机会去学习，去了解当今社会的发展状况及趋势。社会的大发展已决定了个人发展的最大环境、最大上限，制约着可选择度，决定着大学生成功的机率，影响很具体，也很深远。因此，我们应学会认识和把握形势与政策。形势是制定政策的依据，政策影响形势的发展。如今世界飞速发展，各个国家的形势与政策也变化莫测。作为大学生的我们，岂能做那四角的书柜。新时代的接班人就该有自己的思想，不能人云亦云，需要我们形成对形势与政策的洞察力和深刻的理解力，培养超强的把握形势与政策的胆识。以下我将根据课堂上对国际局势和中国原则立场的阐述谈谈我的学习心得。</p><h4 id="一、动荡变革的世界与中国的角色"><a href="#一、动荡变革的世界与中国的角色" class="headerlink" title="一、动荡变革的世界与中国的角色"></a>一、动荡变革的世界与中国的角色</h4><p>当前国际形势波诡云谲，全球政治经济格局正在经历深刻的变动。课堂中指出，地缘政治的紧张、全球经济的复苏困难以及极端气候事件的增多，都是这一时代的特征。而中国，在这一全球变局中所扮演的角色愈发显得至关重要。作为世界的平稳器和连接者，中国在多极世界中积极推动建设性的国际关系，倡导合作共赢的全球治理观。这种外交策略不仅展示了中国的大国担当，也为世界的和平与发展提供了中国智慧和中国方案。</p><h4 id="二、中美关系的新阶段与个人思考"><a href="#二、中美关系的新阶段与个人思考" class="headerlink" title="二、中美关系的新阶段与个人思考"></a>二、中美关系的新阶段与个人思考</h4><p>探究中美关系的稳定与变化，我感受到了这种宏观关系对个人生活轨迹的深远影响。中美之间的每一次微妙平衡，都可能成为影响我未来职业和学术道路的关键因素。在这不断变化的国际环境中，我深知作为学生的我，更应深入学习国际政治经济知识，为未来不可预测的挑战做好准备。</p><h4 id="三、理解多极世界与塑造自我能力"><a href="#三、理解多极世界与塑造自我能力" class="headerlink" title="三、理解多极世界与塑造自我能力"></a>三、理解多极世界与塑造自我能力</h4><p>在多极世界秩序加速整合的今天，了解和适应这种新的国际关系格局，对我们每个人都是一次挑战也是一次机遇。报告中对当前国际秩序的深刻解析，让我认识到，作为新时代的青年，我们需要有开阔的国际视野，更需要有应对复杂国际局势的能力。面对全球性的挑战，如安全、经济和环境问题，作为国际社会的一员，我们每个人都承担着共同的责任。从职业选择到日常行为，每一步都是对全球责任的践行。如何通过自己的专业知识和技能为全球可持续发展做出贡献，成为我深入思考的问题，也是我作为新时代青年的使命所在。</p><p>总之，通过形式与政策这门课的学习，我更加坚信，作为新时代的青年，我们需要站在历史的高度，以开放的心态和包容的姿态，面对全球化带来的挑战和机遇，积极作为，为构建人类命运共同体贡献自己的青春力量。这种力量，源自对和平的渴望，对发展的追求，也源自对美好未来的共同憧憬。</p>]]></content>
      
      
      
        <tags>
            
            <tag> formalism </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Hello World</title>
      <link href="/2024/04/29/hello-world/"/>
      <url>/2024/04/29/hello-world/</url>
      
        <content type="html"><![CDATA[<p>Welcome to <a href="https://hexo.io/">Hexo</a>! This is your very first post. Check <a href="https://hexo.io/docs/">documentation</a> for more info. If you get any problems when using Hexo, you can find the answer in <a href="https://hexo.io/docs/troubleshooting.html">troubleshooting</a> or you can ask me on <a href="https://github.com/hexojs/hexo/issues">GitHub</a>.</p><h2 id="Quick-Start"><a href="#Quick-Start" class="headerlink" title="Quick Start"></a>Quick Start</h2><h3 id="Create-a-new-post"><a href="#Create-a-new-post" class="headerlink" title="Create a new post"></a>Create a new post</h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ hexo new <span class="string">&quot;My New Post&quot;</span></span><br></pre></td></tr></table></figure><p>More info: <a href="https://hexo.io/docs/writing.html">Writing</a></p><h3 id="Run-server"><a href="#Run-server" class="headerlink" title="Run server"></a>Run server</h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ hexo server</span><br></pre></td></tr></table></figure><p>More info: <a href="https://hexo.io/docs/server.html">Server</a></p><h3 id="Generate-static-files"><a href="#Generate-static-files" class="headerlink" title="Generate static files"></a>Generate static files</h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ hexo generate</span><br></pre></td></tr></table></figure><p>More info: <a href="https://hexo.io/docs/generating.html">Generating</a></p><h3 id="Deploy-to-remote-sites"><a href="#Deploy-to-remote-sites" class="headerlink" title="Deploy to remote sites"></a>Deploy to remote sites</h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ hexo deploy</span><br></pre></td></tr></table></figure><p>More info: <a href="https://hexo.io/docs/one-command-deployment.html">Deployment</a></p>]]></content>
      
      
      
    </entry>
    
    
  
  
</search>
