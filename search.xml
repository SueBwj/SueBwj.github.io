<?xml version="1.0" encoding="utf-8"?>
<search> 
  
  
    
    <entry>
      <title>PID控制器的设置</title>
      <link href="/2024/05/23/%E5%AE%9E%E9%AA%8C%E6%8A%A5%E5%91%8A/"/>
      <url>/2024/05/23/%E5%AE%9E%E9%AA%8C%E6%8A%A5%E5%91%8A/</url>
      
        <content type="html"><![CDATA[<h2 id="实验问题"><a href="#实验问题" class="headerlink" title="实验问题"></a>实验问题</h2><ol><li>设计一个阀门控制器，实现对蓄水池的蓄水，假设蓄水池的期望蓄水高度是 1 米,当前水位是 0.2 米，列出来基于 Kp&#x3D;0.5 的 P 控制器的蓄水过程。</li></ol><p>2）如果水池下面被司马光同学砸了一个洞，每个 T 时刻，漏水 0.1 米，那么请问，利用你设计的控制器能把水装满吗？为什么？如何改进？对改进后的效果进行一下讨论。</p><h2 id="实验分析和结果"><a href="#实验分析和结果" class="headerlink" title="实验分析和结果"></a>实验分析和结果</h2><ol><li>通过 Matlab Simulink 设置控制器如下图，其中 Kp&#x3D;0.5，累加器 1&#x2F;s<br>的初始值设置为 0.2，1&#x2F;z 为延迟单元</li></ol><blockquote><p><img src="/PID%E6%8E%A7%E5%88%B6%E5%99%A8%E8%AE%BE%E7%BD%AE/%E5%9B%BE%E7%89%871.png"></p><p>仿真运行结果如下图：蓝色线为水位线随时间变化，橙色线为误差线随时间变化</p><p><img src="/./../PID%E6%8E%A7%E5%88%B6%E5%99%A8%E8%AE%BE%E7%BD%AE/%E5%9B%BE%E7%89%872.png"></p></blockquote><ol><li>(a) 通过 Matlab Simulink 设置控制器如下图，其中 Kp&#x3D;0.5，累加器 1&#x2F;s<br>的初始值设置为 0.2，同时考虑每个 T 时刻，漏水 0.1 米</li></ol><blockquote><p><img src="/./../PID%E6%8E%A7%E5%88%B6%E5%99%A8%E8%AE%BE%E7%BD%AE/%E5%9B%BE%E7%89%873.png"></p><p>仿真运行结果如下图：蓝色线为水位线随时间变化，橙色线为误差线随时间变化</p><p><img src="/./../PID%E6%8E%A7%E5%88%B6%E5%99%A8%E8%AE%BE%E7%BD%AE/%E5%9B%BE%E7%89%874.png">{width&#x3D;”5.768055555555556in”<br>height&#x3D;”4.080555555555556in”}</p><p>由图可得，只使用 P 控制器无法把水装满，最终只能装到 0.8 米处。这是因为水缸中的水位到 0.8 时，则误差 error<br>&#x3D; 1-0.8&#x3D;0.2。<br>所以每次往水缸中加水的量为 u&#x3D;0.5*0.2&#x3D;0.1。同时，每次加水，缸里又会流出去 0.1 米的水，加入的水和流出的水相抵消，水位将不再变化。</p><p>(b)<br>为了消除上述稳态误差，考虑过去误差项，第一次的误差 error 是 0.8，第二次的误差是 0.4，至此，误差的积分 ∫error&#x3D;0.8+0.4&#x3D;1.2.<br>这个时候的控制量，除了比例的那一部分，还有一部分就是一个系数 ki 乘以这个积分项。由于这个积分项会将前面若干次的误差进行累计，所以可以很好的消除稳态误差，使得结果能够达到预期值；通过 Matlab<br>Simulink 设置控制器如下图，将 P 控制器改为 PI 控制器</p></blockquote><p><img src="/./../PID%E6%8E%A7%E5%88%B6%E5%99%A8%E8%AE%BE%E7%BD%AE/%E5%9B%BE%E7%89%875.png"></p><p>从黄色线到蓝色线 Ki 的值分别为 0.2、0.1、0.05,由图观察得，当 Ki 等于 0.05 时，没有超调量，且可以较平稳地收敛到目标值，</p><p><img src="/./../PID%E6%8E%A7%E5%88%B6%E5%99%A8%E8%AE%BE%E7%BD%AE/%E5%9B%BE%E7%89%876.png"></p><p>(c) 考虑使用微分控制器，加快响应速度，降低响应时间</p><p><img src="/./../PID%E6%8E%A7%E5%88%B6%E5%99%A8%E8%AE%BE%E7%BD%AE/%E5%9B%BE%E7%89%877.png"></p><p><img src="/./../PID%E6%8E%A7%E5%88%B6%E5%99%A8%E8%AE%BE%E7%BD%AE/%E5%9B%BE%E7%89%878.png"></p><p>途中蓝色的线是使用 PI 控制器，橙色线使用的是 PID 控制器 Kp &#x3D; 0.5，Ki &#x3D;<br>0.05，Kd &#x3D;<br>0.2，由图可知，使用 PID 控制器的响应时间减少，但是在初始时有一个较大的振荡。但是振荡值在正常范围内。综上，PID 的控制效果最好。</p>]]></content>
      
      
      
        <tags>
            
            <tag> 自动控制原理 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Games of GANs</title>
      <link href="/2024/05/21/Games-of-GANs/"/>
      <url>/2024/05/21/Games-of-GANs/</url>
      
        <content type="html"><![CDATA[<blockquote><p>博弈论期中课程论文撰写: 要求研读至少一篇的有关博弈论想过论文，并写一份报告</p></blockquote><h3 id="研究背景"><a href="#研究背景" class="headerlink" title="研究背景"></a>研究背景</h3><p>生成对抗网络(GANs)是一类生成类模型，首先由 Goodfellow et al.(2014b)提出，该模型因其对高纬度复杂现实数据进行建模的潜力和可以从潜在的空间中生成无限真实的新样本的能力而广泛应用于各个领域，从文本编辑图像、图像合成到计算机视觉、视频再到动画生成和网络安全(Alqahtani et al. 2021)而广受关注。GANs 的核心思想受到零和极大极小博弈的启发，零和极大极小博弈是指一方的收益必然意味着另一方的损失博弈各方的收益和损失相加总和永远为“零”，同时决策者最大化最坏情况下的收益。在 GANs 的框架下有两个模型，一个是判别器，一个是生成器，生成器生成接近于真实数据的分布，让判别器无法判别真实数据和生成数据，而判别器则是识别出生成器生成的数据，直到 GANs 模型达到纳什均衡，在该均衡下，判别器和生成器都无法在不减少对<br>方增益的情况下增加自己的增益。GANs 自从推出以来，受到了广泛的研究，然而 GANs 模型有难以训练，不稳定的问题，例如：模式坍塌、无法收敛和梯度消失等问题(Wang et al. 2019)。GANs 在训练过程中需要收敛到纳什均衡，但这种收敛被证明非常具有挑战性(Wiatrak and Albert 2019)。为了提高 GANs 的能力，改进和完善 GANs 的缺点，有必要从基础原理出发即博弈论的角度去改善 GANs 的性能，但从博弈论视角出发去研究改善 GANs 的研究不多，故该研究有助于丰富 GANs 的研究视角。</p><h3 id="研究方法"><a href="#研究方法" class="headerlink" title="研究方法"></a>研究方法</h3><p>博弈论的三个基本要素为玩家(players)、策略(strategy)、收益(playoff)，改变其中任何一个要素都会影响博弈的进程和结果；因此有许多论文通过改变以上三个要素的一个或多个来实现优化和改进 GANs。</p><ol><li><p><strong>改变博弈模型</strong><br>一些论文认为 GANs 难以训练和收敛是因为传统 GANs 被视作零和极大极小博弈，想要达到纳什均衡非常困难，因此(FA Oliehoek. 2017)将零和极大极小博弈视为有限零和博弈，并根据有限零和博弈的特性：在混合策略的空间中，任何局部纳什均衡都是全局纳什均衡来避免模型陷入局部最优，同时提出资源有限纳什均衡的概念来解决运算量过大和难以收敛的问题。.Farnia et al. in Farnia and Ozdaglar (2020)则认为，先训练判别器，再训练生成器的模式可以被视作斯塔克尔博弈(Stackelberg game)，转而让模型关注到子博弈纳什均衡。</p></li><li><p><strong>改变玩家数量</strong><br>由于 GAN 的训练需要两个模型的共同参与，一旦有任何一个生成器(player)训练失败，就会降低整体的训练效果，即如果判别器判别能力很差，那么生成器就无法根据较好的反馈，生成接近真实数据的分布。根据(Zhanget al. 2018c)提出的具有多生成器架构的 GAN 的极大极小值差距更小，训练性能更加稳定这一论点，许多文章提出了不同的解决方案。</p><h5 id="a-一个生成器多个判别器"><a href="#a-一个生成器多个判别器" class="headerlink" title="(a) 一个生成器多个判别器"></a>(a) 一个生成器多个判别器</h5><p>训练一个过好的判别器会损坏生成器的性能，这是 GAN 面临的一个大难题，如果能够训练多个判别能力没有那么强的判别器，可以提升生<br>成器的性能，并且多个判别器可以相互进行分工，关注图像的不同特征。</p><h5 id="b-一个判别器多个生成器"><a href="#b-一个判别器多个生成器" class="headerlink" title="(b) 一个判别器多个生成器"></a>(b) 一个判别器多个生成器</h5><p>一般来说，生成器相比判别器要完成的任务更难，因为它要完成数据概率密度的拟合，而判别器只需要进行判别，一个判别器一个生成器架构容易产生的一个问题便是“模式坍塌”即生成器由于发现了判别器的盲点，所以为了获得更高的分数就一直生成高度相似的图片，因此多个判别器能够一定程度上防止生成器找到某一个漏洞而持续生成高度相似的图片，能够有效地缓解模式坍塌这个问题。</p></li><li><p><strong>改变学习策略的方法</strong></p><h5 id="a-无悔学习算法-No-regret-learning"><a href="#a-无悔学习算法-No-regret-learning" class="headerlink" title="(a) 无悔学习算法(No-regret learning)"></a>(a) 无悔学习算法(No-regret learning)</h5><p>一般来讲，采用基于后悔值的学习方法以后，每个智能体根据各个行为的后悔值做出行为选择。如果一种算法能够保证最大后悔值渐进的变<br>为零，那么该种算法就可以被称作无悔学习算法。 Grnarova et al.(2017)采用了无悔最小化方法，他们提供了一种可以证明收敛到 MN 均衡的方法。因为生成者纯策略的最小值总是高于生成者混合均衡策略的最小值</p><h5 id="b-虚拟博弈-Fictitious-Play"><a href="#b-虚拟博弈-Fictitious-Play" class="headerlink" title="(b) 虚拟博弈(Fictitious Play)"></a>(b) 虚拟博弈(Fictitious Play)</h5><p>虚拟博弈常被用来解决零和博弈问题，其基本思想是：使每个智能体拥有两个策略集。一个是最优策略集，一个是历史平均策略集。在每一轮博弈的开始，每个均智能体根据对手的历史平均策略集，找到一个最优的针对策略。然后根据历史平均策略和本轮最优策略更新自己的历史平均策略。Ge at al.（2018）设计了一种训练算法来模拟 GAN 上的虚构游戏，并提供了理论上的收敛保证。他们还表明，通过在虚构 GAN 中每次更新时假设最佳响应，生成器的混合输出分布会收敛到数据分布。判别器输出收敛于最佳判别器函数。Ge at al.（2018）中的作者使用两个队列 D 和 G 来存储判别器和生成器的历史训练模型。他们还表明，虚构 GAN 可以有效解决标准训练方法无法解决的一些收敛问题，并可应用于现有的 GAN 变体之上。</p></li></ol><h3 id="结论"><a href="#结论" class="headerlink" title="结论"></a>结论</h3><p>该研究从 GAN 的原理出发，论述了 GAN 的原理、应用和训练上遇到的种种问题如：难以收敛、模式坍塌等，文章认为想要更好的改善这些问题，需要从 GAN 的原理出发，即零和极大极小博弈，从博弈论的三个核心要素：玩家(players)、策略(strategy)、收益(playoff)上出发对 GAN 的改进和优化。</p><h3 id="参考文献"><a href="#参考文献" class="headerlink" title="参考文献"></a>参考文献</h3><ol><li>Goodfellow, I., Pouget-Abadie, J., Mirza, M., Xu, B., Warde-Farley, D., Ozair, S., … &amp; Bengio,<br>Y. (2014). Generative adversarial nets. Advances in neural information processing<br>systems, 27.</li><li>Alqahtani, H., Kavakli-Thorne, M., &amp; Kumar, G. (2021). Applications of generative<br>adversarial networks (gans): An updated review. Archives of Computational Methods in<br>Engineering, 28, 525-552.</li><li>Wang, Z., She, Q., &amp; Ward, T. E. (2021). Generative adversarial networks in computer<br>vision: A survey and taxonomy. ACM Computing Surveys (CSUR), 54(2), 1-38.</li><li>Wiatrak, M., Albrecht, S. V., &amp; Nystrom, A. (2019). Stabilizing generative adversarial<br>networks: A survey. arXiv preprint arXiv:1910.00927.</li><li>Oliehoek, F. A., Savani, R., Gallego-Posada, J., Van der Pol, E., De Jong, E. D., &amp; Groß,<br>R. (2017). GANGs: Generative adversarial network games. arXiv preprint<br>arXiv:1712.00679.</li><li>Farnia, F., &amp; Ozdaglar, A. (2020). Gans may have no nash equilibria. arXiv preprint<br>arXiv:2002.09124.</li><li>Zhang, H., Xu, S., Jiao, J., Xie, P., Salakhutdinov, R., &amp; Xing, E. P. (2018). Stackelberg<br>GAN: Towards provable minimax equilibrium via multi-generator architectures. arXiv<br>preprint arXiv:1811.08010.</li><li>Grnarova, P., Levy, K. Y., Lucchi, A., Hofmann, T., &amp; Krause, A. (2017). An online learning<br>approach to generative adversarial networks. arXiv preprint arXiv:1706.03269.</li></ol>]]></content>
      
      
      
        <tags>
            
            <tag> 博弈论课程 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>GAN</title>
      <link href="/2024/05/21/GAN/"/>
      <url>/2024/05/21/GAN/</url>
      
        <content type="html"><![CDATA[<h3 id="Network-as-Generator"><a href="#Network-as-Generator" class="headerlink" title="Network as Generator"></a>Network as Generator</h3><p>输入新增加一个 Z，Z 来源(sample)于一个简单的 distribution，通过神经网络的转化之后输出一个复杂的 distribution，那么这个 network 就被称为<strong>generator</strong><br><img src="/../GAN_imgs/Untitled.png" alt="Untitled"></p><blockquote><p>❓ 那为什么要生成一个分布呢？</p></blockquote><ol><li>让神经网络的输出不再是一个<strong>单一</strong>的输出，而是输出一个概率分布，这个分布包含了很多的可能性，解决这个世界有很多不可预测确定值的问题</li><li>需要一个 function，同样的输入有很多不同的输出 → 让机器具有创造力（draw，chatbot）</li></ol><h3 id="Generative-Adversarial-Network-GAN"><a href="#Generative-Adversarial-Network-GAN" class="headerlink" title="Generative Adversarial Network(GAN)"></a>Generative Adversarial Network(GAN)</h3><blockquote><p>🦁 <a href="https://github.com/hindupuravinash/the-gan-zoo">https://github.com/hindupuravinash/the-gan-zoo</a> - gan 的动物园</p></blockquote><ul><li><p>Anime Face Generator</p><ol><li>没有 x 输入，只输入 z</li><li>simple distribution 的选择产生的差异不是很大<br><img src="/../GAN_imgs/Untitled%201.png" alt="Untitled"></li></ol></li><li><p>Anime Face Discriminator</p><ol><li>因为输入的是一张图片，所以大概率会选择 CNN<br><img src="/../GAN_imgs/Untitled%202.png" alt="Untitled"></li></ol></li><li><p>Basic Idea of GAN<br>GANs 的核心思想受到零和极大极小博弈的启发，零和极大极小博弈是指一方的收益必然意味着另一方的损失博弈各方的收益和损失相加总和永远为“零”，同时决策者最大化最坏情况下的收益。在 GANs 的框架下有两个模型，一个是判别器，一个是生成器，生成器生成接近于真实数据的分布，让判别器无法判别真实数据和生成数据，而判别器则是识别出生成器生成的数据，直到 GANs 模型达到纳什均衡，在该均衡下，判别器和生成器都无法在不减少对方增益的情况下增加自己的增益。</p><ul><li>Anime Face Generator vs Anime Face Discriminator<br><img src="/../GAN_imgs/Untitled%203.png" alt="Untitled"></li></ul></li><li><p>Algorithm</p><ol><li><p>Initialize generator and discriminator</p></li><li><p>In each training iteration</p><ol><li><strong>step1:</strong> Fix generator G, and update discriminator D<ul><li>Discriminator learns to assign high scores to real objects and low scores to generated objects. - 可以当作分类问题也可以当作回归问题</li></ul></li><li><strong>step2:</strong> Fix discriminator D and update generator G<ul><li>训练的目标是让 discriminator 打的分越高越好，generator learns to “fool” the discriminator<br><img src="/../GAN_imgs/Untitled%204.png" alt="Untitled"></li></ul></li></ol></li></ol><blockquote><p>💡 训练一阵子 genrator，训练一阵子 discriminator</p></blockquote></li></ul><h3 id="Theory-behind-GAN"><a href="#Theory-behind-GAN" class="headerlink" title="Theory behind GAN"></a>Theory behind GAN</h3><ul><li><p>训练目标</p><ul><li><p>生成器(generator)的目标</p><ul><li>真实数据的分布和生成器生成的数据分布越接近越好<br>在 generator 中 loss function 就是 divergence(P_G, P_data)<br><img src="/../GAN_imgs/Untitled%205.png" alt="Untitled"></li><li>但是如何计算 divergence？ — 无法计算，需要找别的方法<br>采用<strong>Sample</strong>的方法<br><img src="/../GAN_imgs/Untitled%206.png" alt="Untitled"></li></ul></li><li><p>判别器(discriminator)的目标<br><img src="/../GAN_imgs/Untitled%207.png" alt="Untitled"><br>等同于训练一个<strong>Classifier</strong></p><blockquote><p>💡 discriminator 计算出来的 argmaxV(D,G)的值和 divergence 是相关的，即 maxV(D,G)的值越小，则说明真实数据和生成数据非常接近，因此 discriminator 的目标函数也可以作为评价 generator 的指标</p></blockquote><p><img src="/../GAN_imgs/Untitled%208.png" alt="Untitled"></p></li></ul></li><li><p>GAN is difficult to train — <strong>tips</strong> to train GAN</p><ul><li>JS divergence is not suitable<br><img src="/../GAN_imgs/Untitled%209.png" alt="Untitled"><ul><li>对于两个没有重叠的分布对 js divergence 有什么影响<br>尽管 P_G 和 P_data 越来越接近，但是如果使用二分类的 discriminator 无法提供任何信息<br><img src="/../GAN_imgs/Untitled%2010.png" alt="Untitled"></li></ul></li><li>Wasserstein distance — 用于处理先前 JS divergence 的问题<ul><li>可以反映出 generator 是否比先前更好<br><img src="/../GAN_imgs/Untitled%2011.png" alt="Untitled"></li><li>WGAN<ul><li>D 采样的值必须要平滑，不能够变化剧烈，要不然如果值很大，但是每次只变化一点，那就没法判断 generator 是否变好，就会变成和 JS divergence 一样的问题<br><img src="/../GAN_imgs/Untitled%2012.png" alt="Untitled"></li><li>那么满足足够平滑这个条件呢？<ul><li>Gradient Penalty</li><li>Spectral Normalization</li></ul></li></ul></li></ul></li></ul></li></ul><h3 id="GAN-is-still-challenging-—-difficult-to-train"><a href="#GAN-is-still-challenging-—-difficult-to-train" class="headerlink" title="GAN is still challenging — difficult to train"></a>GAN is still challenging — difficult to train</h3><blockquote><p>❓ 用 GAN 生成一段文字是最困难的</p></blockquote><blockquote><p>❓ 无法使用 gradient descent 的模型可以考虑使用 reinforcment training</p></blockquote><h3 id="Evalution-of-GAN"><a href="#Evalution-of-GAN" class="headerlink" title="Evalution of GAN"></a>Evalution of GAN</h3><ul><li>Human evaluation is expensive (and sometimes unfair&#x2F;unstable) <strong>??</strong></li><li>How to evaluate the quality of the generated images automatically <strong>??</strong></li><li>Mode Collapse(模式坍塌)<ul><li>generate 总是生成相同的图片，因为发现可能这个图片是 discriminator 的盲点，所以为了获得更高的分数就一直生成这些图片<br><img src="/../GAN_imgs/Untitled%2013.png" alt="Untitled"></li><li>今天还没有一个非常好的办法解决 mode collapse</li></ul></li><li>Diversity - Mode Dropping<br><img src="/../GAN_imgs/Untitled%2014.png" alt="Untitled"></li><li>使用影像分类器 — Good quality<br>输出的分布越集中，说明效果越好<br><img src="/../GAN_imgs/Untitled%2015.png" alt="Untitled"></li><li>如何检测多样性 — large diversity<ul><li>每一张图片丢到图像分类器都识别出 class2<br><img src="/../GAN_imgs/Untitled%2016.png" alt="Untitled"></li><li>丢不同的图片的时候识别的 class 都不太一样，说明是具备 diversity<br><img src="/../GAN_imgs/Untitled%2017.png" alt="Untitled"></li></ul></li></ul><blockquote><p>💡 Good quality 是根据一张图片，large diversity 是根据很多张图片取平均 （IS）</p></blockquote><ul><li><p>FID — Frechet Inception Distance</p><ul><li>计算距离比较相似度 — samller is better<br><img src="/../GAN_imgs/Untitled%2018.png" alt="Untitled"></li></ul></li><li><p>加入产生的图片和训练资料的图片一模一样 —&gt; Memory GAN<br><img src="/../GAN_imgs/Untitled%2019.png" alt="Untitled"></p><blockquote><p>💡 因此评估 GAN 非常困难</p></blockquote></li><li><p>Condition Generator</p><ul><li>作用 — Text-to-image — supervise learning<br><img src="/../GAN_imgs/Untitled%2020.png" alt="Untitled"><ul><li>discriminator 要同时接受图片和文本，只有图片和文本是相配的，才能拿高分；但是一般这样训练出来的结果不够好<br><img src="/../GAN_imgs/Untitled%2021.png" alt="Untitled"></li><li>为了改进上述的问题，需要加入负样本<br><img src="/../GAN_imgs/Untitled%2022.png" alt="Untitled"></li></ul></li><li>图片的风格转化 — image translation<br><img src="/../GAN_imgs/Untitled%2023.png" alt="Untitled"></li></ul></li></ul><h3 id="Learning-from-Unpair-Data"><a href="#Learning-from-Unpair-Data" class="headerlink" title="Learning from Unpair Data"></a>Learning from Unpair Data</h3><blockquote><p>💡 把 GANs 运用到 unsupurised learning</p></blockquote><ul><li><p>使用未标注，不成对的数据</p><ol><li><p>有一部分资料是成对的</p><p>pseudo labeling、back translation</p></li><li><p>完全没有成对的资料 - 影像风格转化</p><p><img src="/../GAN_imgs/Untitled%2024.png" alt="Untitled"></p></li></ol></li><li><p>如何使用 GANs<br>用 network 将 domain x 的东西转化为 domain y<br><img src="/../GAN_imgs/Untitled%2025.png" alt="Untitled"></p></li><li><p>Cycle GAN<br>discriminator 判断图片是否属于 y domain，但是仅仅判断是否属于 y domain 还不够，需要输入与输出有关系，考虑使用 conditional GAN，但是也没有办法直接套用 conditional GAN，因为没有成对的资料<br><img src="/../GAN_imgs/Untitled%2026.png" alt="Untitled"><br>使用两个 generator，一个 generator 将 x domain 转化为 y domain，另一个 generator 将 y domain 转化为 x domain，然后比较两个图片的距离，越接近越好。加入 cycle，可以保证 y domain 的输出与 x domain 输入有关<br><img src="/../GAN_imgs/Untitled%2027.png" alt="Untitled"><br>双向的 cycle GAN<br><img src="/../GAN_imgs/Untitled%2028.png" alt="Untitled"></p></li></ul>]]></content>
      
      
      
        <tags>
            
            <tag> 李宏毅机器学习 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>CNN</title>
      <link href="/2024/05/14/CNN/"/>
      <url>/2024/05/14/CNN/</url>
      
        <content type="html"><![CDATA[<h3 id="Neuron-Version-Story"><a href="#Neuron-Version-Story" class="headerlink" title="Neuron Version Story"></a>Neuron Version Story</h3><ul><li>一张图片是 3 维的 tensor，(channel, height, weight)。channel 表示 rgb 三通道；将图片的三维压缩成一维度向量输入到神经网络<br><img src="/../CNN_img/Untitled.png" alt="Untitled"></li><li>如果使用<strong>Fully Connected Network</strong>，需要的参数量非常巨大，输入向量长度为 100 X 100 X 3， 神经元个数是 1000 个，模型参数越多，越容易 overfiting</li><li>Observation1<ul><li>神经元的作用：Identifying some critical patterns，发现一些重要的特征<br><img src="/../CNN_img/Untitled%201.png" alt="Untitled"></li><li>Some patterns are much smaller than the whole image.特征只占图片的一小部分<ol><li>每一个 neural 只关注一小部分（receptive field）就好了</li><li>receptive field 可以重叠</li><li>receptive field 可以只 cover 部分 channel</li><li>receptive field 不一定要是正方形<br><img src="/../CNN_img/Untitled%202.png" alt="Untitled"><br><img src="/../CNN_img/Untitled%203.png" alt="Untitled"></li></ol></li><li>Typical Setting<ol><li>考虑所有的 channel</li><li>receptive field 也被称为 kernel size，一般设置为 3*3</li><li>同一个 receptive field 会有一组，一排去检测它（64 个神经元）</li><li>stride 表示每个 receptive field 之间的间隔是多少 （stride &#x3D; 2），最好每个 receptive field 之间有一定的重叠</li><li>receptive field 有一部分超出了图片的范围，那么就用 padding 来补充<br><img src="/../CNN_img/Untitled%204.png" alt="Untitled"></li></ol></li></ul></li><li>Observation2:<ul><li>The same patterns appear in different regions<ul><li>每一个 receptive field 都有一个侦测鸟嘴的神经元 → 问题：参数量太多了<br><img src="/../CNN_img/Untitled%205.png" alt="Untitled"></li><li>解决方案：<strong>参数共享</strong>，虽然参数一样，但是输入是不一样的，所以输出是不一样的<br><img src="/../CNN_img/Untitled%206.png" alt="Untitled"></li><li>Typical Setting - 常见的共享参数的方法<br><img src="/../CNN_img/Untitled%207.png" alt="Untitled"></li></ul></li></ul></li></ul><h3 id="Convolution-Layer-—-another-story-based-on-filter"><a href="#Convolution-Layer-—-another-story-based-on-filter" class="headerlink" title="Convolution Layer — another story based on filter"></a>Convolution Layer — another story based on filter</h3><ol><li>从图片中去抓取 pattern</li></ol><ul><li>计算方式<br><img src="/../CNN_img/Untitled%208.png" alt="表明左上角和左下角都出现了这个pattern"><br>表明左上角和左下角都出现了这个 pattern</li><li>future map<br>如果有 64 个 filter，那么就会有 64<em>4</em>4 的矩阵，可以把这个 future map 理解成一张新的图片，有 64 个 channel<br><img src="/../CNN_img/Untitled%209.png" alt="Untitled"></li></ul><ol><li>如果 network 足够深，filter 能够看到足够大的 pattern</li></ol><ul><li><strong>Observation3</strong><ol><li>Subsampling the pixels will not change the object - 放大缩小(减去行和列的条数)图片不会对图像内容造成影响</li></ol><ul><li>Pooling - Max Pooling<ul><li>Pooling 的作用 - 减少运算量，如果运算量足够强，也可以不做 pooling<br><img src="/../CNN_img/Untitled%2010.png" alt="Untitled"></li><li>Convolutional Layers + Pooling<br><img src="/../CNN_img/Untitled%2011.png" alt="Untitled"></li></ul></li></ul></li></ul><h3 id="The-whole-CNN"><a href="#The-whole-CNN" class="headerlink" title="The whole CNN"></a>The whole CNN</h3><p><img src="/../CNN_img/Untitled%2012.png" alt="Untitled"></p><p><img src="/../CNN_img/Untitled%2013.png" alt="Untitled"></p><blockquote><p>❓ CNN 无法处理放大和缩小之后或旋转的图像，CNN is not invariant to scaling and rotation</p></blockquote><blockquote><p>💡 通过影像的特性来对模型进行限制，避免 overfitting</p></blockquote><h3 id="改善-CNN-的方法"><a href="#改善-CNN-的方法" class="headerlink" title="改善 CNN 的方法"></a>改善 CNN 的方法</h3><p>→ need data augmentation — 处理旋转问题</p><p>→ 处理放大缩小问题 — Spatial Transformer Layer</p>]]></content>
      
      
      
        <tags>
            
            <tag> 李宏毅机器学习 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Framework of ML</title>
      <link href="/2024/05/14/Framework%20of%20ML%208c9833550a9e4691b4fe4a8532ac1d84/"/>
      <url>/2024/05/14/Framework%20of%20ML%208c9833550a9e4691b4fe4a8532ac1d84/</url>
      
        <content type="html"><![CDATA[<ul><li><p>训练过程<br><img src="/../Framework_of_ml/Untitled.png" alt="Untitled"></p></li><li><p>训练方法—如何调整神经网络让效果更好<br><img src="/../Framework_of_ml/Untitled%201.png" alt="Untitled"></p><ul><li><p>首先检查 training data loss：判断在训练资料是否学好了</p><ol><li><p>如果没有学好：可以考虑<strong>model bias</strong></p><ul><li><p>model bias</p><ul><li><p>the model is too simple</p><blockquote><p>💡 solution: redesign your model to make it more flexible，重新设计模型</p></blockquote><p><img src="/../Framework_of_ml/Untitled%202.png" alt="Untitled"></p></li></ul></li></ul></li><li><p>也可能是<strong>optimization issue</strong>，陷入到局部最优之中</p></li><li><p>如何判断是 model bias 的问题，即模型不够大，还是 optimization 选取的不够好？通过比较判断</p><p><img src="/../Framework_of_ml/Untitled%203.png" alt="Untitled"></p><blockquote><p>💡 56 层网络的表达能力更强，肯定可以选出合适的 function，得到和 20 层一样低的 loss，所以这里是 optimization 的 issue</p></blockquote><ul><li>Gaining the insights from comparison</li><li>Start from shallower networks(or other models), which are eaiser to optimization</li><li>if deeper networks do not obtain smaller loss on training data, then there is optimization issue<br><img src="/../Framework_of_ml/Untitled%204.png" alt="Untitled"></li></ul></li></ol></li><li><p>如果<strong>training data loss</strong>足够小了，则可以来判断<strong>testing data loss</strong></p><ol><li>如果小就结束了</li></ol><ul><li><p>如果在<strong>testing data loss</strong>很大的话，就可以考虑 overfitting<br><img src="/../Framework_of_ml/Untitled%205.png" alt="Untitled"><br><img src="/../Framework_of_ml/Untitled%206.png" alt="Untitled"></p><blockquote><p>❓ 比较有弹性的 model 跟家容易 overfitting</p></blockquote><ul><li><p>如何解决 overfitting</p><ul><li><p>增加训练资料<br><img src="/../Framework_of_ml/Untitled%207.png" alt="Untitled"></p></li><li><p>data augmentation-根据自己对数据的理解，增加新的训练数据，要 augment 的有道理<br><img src="/../Framework_of_ml/Untitled%208.png" alt="Untitled"><br>上下翻转的猫猫不会出现在现实世界里</p></li><li><p>增加限制 - 正则化 - 也取决与对 model 的理解<br><img src="/../Framework_of_ml/Untitled%209.png" alt="Untitled"></p><blockquote><p>💡 Less Parameters, sharing parameters, early stopping, regularization, dropout</p></blockquote></li><li><p>限制也不能太大<br><img src="/../Framework_of_ml/Untitled%2010.png" alt="Untitled"><br>限制过多又会导致模型弹性不够的问题</p></li><li><p>Bias-Complexity Trade-off<br><img src="/../Framework_of_ml/Untitled%2011.png" alt="Untitled"></p></li></ul></li></ul></li><li><p>除此之外还可以考虑 mismatch</p><ul><li>Your training and testing data have <strong>different distributions</strong></li></ul></li></ul></li></ul></li><li><p>判断模型好坏的方法—cross validation<br><img src="/../Framework_of_ml/Untitled%2012.png" alt="Untitled"><br><img src="/../Framework_of_ml/Untitled%2013.png" alt="Untitled"></p></li></ul>]]></content>
      
      
      
        <tags>
            
            <tag> 李宏毅机器学习 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Saddle Point and Local Minima</title>
      <link href="/2024/05/14/Saddle%20Point%20and%20Local%20minima/"/>
      <url>/2024/05/14/Saddle%20Point%20and%20Local%20minima/</url>
      
        <content type="html"><![CDATA[<ul><li><p>Optimization Fails beacause</p><ul><li>local minima（no way to go） 和 saddle point （can escape）统称为 critical point<br><img src="/../Saddlepoint/Untitled.png" alt="Untitled"></li></ul></li><li><p>如何判断是 local minima 还是 saddle point</p><ul><li><p>Tayler Series Approximation - 通过泰勒近似，求出损失函数的近似，gradient 为一次积分，hessian 为二次积分<br><img src="/../Saddlepoint/Untitled%201.png" alt="Untitled"></p></li><li><p>因为 local minima 和 saddle 都是 gradient 为 0 的点，所以通过 Hessian 来判断<br><img src="/../Saddlepoint/Untitled%202.png" alt="Untitled"></p></li><li><p>一个例子：data 为输入 1，输出为 1<br><img src="/../Saddlepoint/Untitled%203.png" alt="Untitled"></p></li><li><p>如果是一个 saddle point 的时候，H 可以告诉我们 Parameter update direction<br><img src="/../Saddlepoint/Untitled%204.png" alt="Untitled"><br><img src="/../Saddlepoint/Untitled%205.png" alt="Untitled"></p><blockquote><p>💡 一般不会去算 Hessian, 还有其他方法，因为计算 Hessian 的计算量要求很大</p></blockquote></li></ul></li><li><p>Saddle Point vs Local Minima</p><blockquote><p>💡 也许当前碰到的 local minima 或 saddle point 只是在当前维度下，也许升高维度就会有路可以走</p></blockquote></li></ul>]]></content>
      
      
      
        <tags>
            
            <tag> 李宏毅机器学习 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Optimization</title>
      <link href="/2024/05/14/Optimization/"/>
      <url>/2024/05/14/Optimization/</url>
      
        <content type="html"><![CDATA[<h3 id="Optimization："><a href="#Optimization：" class="headerlink" title="Optimization："></a>Optimization：</h3><ul><li>What is Optimization about<ul><li>找到一个神经网络的参数，让 y_hat 和 y 很接近，也就是让 loss 最小</li><li>on-line learning: 每一个 time step 只能看到当前的 x_t</li><li>off-line learning： 一次可以拿到所有的训练资料</li></ul></li><li>SGD<br><img src="/../Optimization/Untitled.png" alt="Untitled"></li><li>SGD with Momentum(SGDM)<br><img src="/../Optimization/Untitled%201.png" alt="Untitled"><br><img src="/../Optimization/Untitled%202.png" alt="Untitled"></li><li>Adagrad<ul><li>如果过去的 gradient 很大，说明当前的下降的路比较陡，那么分母就会比较大，那么每次走的步数比较小<br><img src="/../Optimization/Untitled%203.png" alt="Untitled"></li></ul></li><li>RMSProp<ul><li>解决 Adagrad 的问题，如果初始的 gradient 就特别大，那么就会导致 learning rate 非常的小，很有可能就卡着不动了，所以这里除以的分母是一个和时间相关联的量<br><img src="/../Optimization/Untitled%204.png" alt="Untitled"></li></ul></li><li>Adam<br><img src="/../Optimization/Untitled%205.png" alt="Untitled"></li></ul><h3 id="Application"><a href="#Application" class="headerlink" title="Application"></a>Application</h3><ul><li>Adam vs SGDM<br><img src="/../Optimization/Untitled%206.png" alt="Untitled"></li><li>Simple combine Adam with SGDM → SWATS<br><img src="/../Optimization/Untitled%207.png" alt="Untitled"></li></ul>]]></content>
      
      
      
        <tags>
            
            <tag> 李宏毅机器学习 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>使用 google-colab 云端训练</title>
      <link href="/2024/05/12/%E4%BD%BF%E7%94%A8google-colab/"/>
      <url>/2024/05/12/%E4%BD%BF%E7%94%A8google-colab/</url>
      
        <content type="html"><![CDATA[<ol><li>将代码和数据集压缩载入到 google colab，上传完毕后解压</li></ol><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">!unzip /content/yolo.<span class="built_in">zip</span> -d /content/yolov5</span><br></pre></td></tr></table></figure><ol><li>需要删除文件_MACOSX(一些关于操作系统的配置)</li></ol><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">!rm -rf /content/_MACOSX</span><br></pre></td></tr></table></figure><ol><li>进入到代码目录</li></ol><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">%cd /content/yolov5/yolov5-<span class="number">5.0</span></span><br></pre></td></tr></table></figure><ol><li>安装依赖包文件</li></ol><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">!pip install -r requirements.txt</span><br></pre></td></tr></table></figure><ol><li>启动 tensorboard</li></ol><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">%load_ext tensorboard</span><br><span class="line"><span class="comment"># 如果想要重新加载就使用reload_ext</span></span><br><span class="line"></span><br><span class="line">%tensorboard --logdir=runs/train</span><br></pre></td></tr></table></figure><ol><li>运行 train.py 文件</li></ol><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">!python train.py --rect</span><br></pre></td></tr></table></figure>]]></content>
      
      
      
        <tags>
            
            <tag> 深度学习 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>形式与政策</title>
      <link href="/2024/05/05/%E5%BD%A2%E5%BC%8F%E4%B8%8E%E6%94%BF%E7%AD%96/"/>
      <url>/2024/05/05/%E5%BD%A2%E5%BC%8F%E4%B8%8E%E6%94%BF%E7%AD%96/</url>
      
        <content type="html"><![CDATA[<p>💀 一直对学校中形式主义的教学和任务深恶痛绝，为减轻他人负担，故分享 <strong>此文章由 GPT4 生成，可随性引用</strong></p><h1 id="琢磨全球风云：新时代大学生的国际视野与责任担当"><a href="#琢磨全球风云：新时代大学生的国际视野与责任担当" class="headerlink" title="琢磨全球风云：新时代大学生的国际视野与责任担当"></a>琢磨全球风云：新时代大学生的国际视野与责任担当</h1><p>作为新时代大学生，“风声雨声读书声，声声入耳；家事国事天下事，事事关心”是对我们最基本的要求。而《形式与政策》这门课程给了我一个机会去学习，去了解当今社会的发展状况及趋势。社会的大发展已决定了个人发展的最大环境、最大上限，制约着可选择度，决定着大学生成功的机率，影响很具体，也很深远。因此，我们应学会认识和把握形势与政策。形势是制定政策的依据，政策影响形势的发展。如今世界飞速发展，各个国家的形势与政策也变化莫测。作为大学生的我们，岂能做那四角的书柜。新时代的接班人就该有自己的思想，不能人云亦云，需要我们形成对形势与政策的洞察力和深刻的理解力，培养超强的把握形势与政策的胆识。以下我将根据课堂上对国际局势和中国原则立场的阐述谈谈我的学习心得。</p><h4 id="一、动荡变革的世界与中国的角色"><a href="#一、动荡变革的世界与中国的角色" class="headerlink" title="一、动荡变革的世界与中国的角色"></a>一、动荡变革的世界与中国的角色</h4><p>当前国际形势波诡云谲，全球政治经济格局正在经历深刻的变动。课堂中指出，地缘政治的紧张、全球经济的复苏困难以及极端气候事件的增多，都是这一时代的特征。而中国，在这一全球变局中所扮演的角色愈发显得至关重要。作为世界的平稳器和连接者，中国在多极世界中积极推动建设性的国际关系，倡导合作共赢的全球治理观。这种外交策略不仅展示了中国的大国担当，也为世界的和平与发展提供了中国智慧和中国方案。</p><h4 id="二、中美关系的新阶段与个人思考"><a href="#二、中美关系的新阶段与个人思考" class="headerlink" title="二、中美关系的新阶段与个人思考"></a>二、中美关系的新阶段与个人思考</h4><p>探究中美关系的稳定与变化，我感受到了这种宏观关系对个人生活轨迹的深远影响。中美之间的每一次微妙平衡，都可能成为影响我未来职业和学术道路的关键因素。在这不断变化的国际环境中，我深知作为学生的我，更应深入学习国际政治经济知识，为未来不可预测的挑战做好准备。</p><h4 id="三、理解多极世界与塑造自我能力"><a href="#三、理解多极世界与塑造自我能力" class="headerlink" title="三、理解多极世界与塑造自我能力"></a>三、理解多极世界与塑造自我能力</h4><p>在多极世界秩序加速整合的今天，了解和适应这种新的国际关系格局，对我们每个人都是一次挑战也是一次机遇。报告中对当前国际秩序的深刻解析，让我认识到，作为新时代的青年，我们需要有开阔的国际视野，更需要有应对复杂国际局势的能力。面对全球性的挑战，如安全、经济和环境问题，作为国际社会的一员，我们每个人都承担着共同的责任。从职业选择到日常行为，每一步都是对全球责任的践行。如何通过自己的专业知识和技能为全球可持续发展做出贡献，成为我深入思考的问题，也是我作为新时代青年的使命所在。</p><p>总之，通过形式与政策这门课的学习，我更加坚信，作为新时代的青年，我们需要站在历史的高度，以开放的心态和包容的姿态，面对全球化带来的挑战和机遇，积极作为，为构建人类命运共同体贡献自己的青春力量。这种力量，源自对和平的渴望，对发展的追求，也源自对美好未来的共同憧憬。</p>]]></content>
      
      
      
        <tags>
            
            <tag> formalism </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Hello World</title>
      <link href="/2024/04/29/hello-world/"/>
      <url>/2024/04/29/hello-world/</url>
      
        <content type="html"><![CDATA[<p>Welcome to <a href="https://hexo.io/">Hexo</a>! This is your very first post. Check <a href="https://hexo.io/docs/">documentation</a> for more info. If you get any problems when using Hexo, you can find the answer in <a href="https://hexo.io/docs/troubleshooting.html">troubleshooting</a> or you can ask me on <a href="https://github.com/hexojs/hexo/issues">GitHub</a>.</p><h2 id="Quick-Start"><a href="#Quick-Start" class="headerlink" title="Quick Start"></a>Quick Start</h2><h3 id="Create-a-new-post"><a href="#Create-a-new-post" class="headerlink" title="Create a new post"></a>Create a new post</h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ hexo new <span class="string">&quot;My New Post&quot;</span></span><br></pre></td></tr></table></figure><p>More info: <a href="https://hexo.io/docs/writing.html">Writing</a></p><h3 id="Run-server"><a href="#Run-server" class="headerlink" title="Run server"></a>Run server</h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ hexo server</span><br></pre></td></tr></table></figure><p>More info: <a href="https://hexo.io/docs/server.html">Server</a></p><h3 id="Generate-static-files"><a href="#Generate-static-files" class="headerlink" title="Generate static files"></a>Generate static files</h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ hexo generate</span><br></pre></td></tr></table></figure><p>More info: <a href="https://hexo.io/docs/generating.html">Generating</a></p><h3 id="Deploy-to-remote-sites"><a href="#Deploy-to-remote-sites" class="headerlink" title="Deploy to remote sites"></a>Deploy to remote sites</h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ hexo deploy</span><br></pre></td></tr></table></figure><p>More info: <a href="https://hexo.io/docs/one-command-deployment.html">Deployment</a></p>]]></content>
      
      
      
    </entry>
    
    
  
  
</search>
