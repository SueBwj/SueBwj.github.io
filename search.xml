<?xml version="1.0" encoding="utf-8"?>
<search> 
  
  
    
    <entry>
      <title>SD-Turbo</title>
      <link href="/2025/08/17/SD-turbo/"/>
      <url>/2025/08/17/SD-turbo/</url>
      
        <content type="html"><![CDATA[<ol><li><p><strong>生成速度 (Generation Speed)</strong></p><p>SD-Turbo: 实现了单步图像生成。这意味着它只需要一次网络前向传播就能输出最终图像，大大缩短了生成时间，使其适用于实时交互应用。<br>其他扩散模型 (如 Stable Diffusion 1.5/2.1, SDXL): 通常需要一个迭代的“去噪”过程，步数（Steps）一般设置在 20 到 50 步之间。步数越多，细节通常越好，但耗时也越长。</p></li><li><p><strong>实现技术 (Underlying Technology)</strong></p><p>SD-Turbo: 采用了一种名为对抗性扩散蒸馏 (Adversarial Diffusion Distillation, ADD) 的新技术。<br>可以将其理解为一种“模型蒸馏”技术。它有一个强大的“教师模型”（基于 SD 2.1），SD-Turbo 作为“学生模型”来学习教师的生成能力。<br>与传统蒸馏不同，它引入了对抗性训练（类似 GANs），有一个判别器来判断生成图像的真伪，这迫使 SD-Turbo 学会在单步内就生成非常逼真的图像。<br>其他扩散模型: 使用的是扩散与去噪（Denoising Diffusion Probabilistic Models, DDPM）原理。通过一个逐步添加噪声的前向过程和一个逐步去除噪声的反向过程来生成图像，这个反向过程就是我们通常所说的采样（sampling）。</p></li><li><p><strong>图像质量与细节 (Image Quality &amp; Detail)</strong></p><p>SD-Turbo: 在单步生成的前提下，图像质量非常惊人，但在精细的细节、复杂构图和对提示词（Prompt）的精确理解上，可能略逊于经过多步迭代的顶级模型（如 SDXL）。它在速度和质量之间做了一个极致的平衡。<br>其他扩散模型: 可以通过增加迭代步数来提升图像的细节和一致性，通常能够更好地遵循复杂的提示词。SDXL 在这方面尤其出色。</p></li><li><p><strong>使用方式 (Usage)</strong></p><p>SD-Turbo: 在使用时，通常不需要或不推荐使用 guidance_scale (CFG) 和 negative_prompt。因为它的模型设计就是为了在单步内直接生成，没有多步迭代的过程给这些参数来引导。通常会将 guidance_scale 设置为 0。<br>其他扩散模型: guidance_scale 和 negative_prompt 是非常重要的控制手段，用来增强提示词的相关性并避免不希望出现的元素。</p></li></ol>]]></content>
      
      
      <categories>
          
          <category> Learning </category>
          
      </categories>
      
      
        <tags>
            
            <tag> AI </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Alignment Module</title>
      <link href="/2025/08/17/AlignmentModule/"/>
      <url>/2025/08/17/AlignmentModule/</url>
      
        <content type="html"><![CDATA[<h2 id="计算机视觉领域的-Alignment-Module-设计"><a href="#计算机视觉领域的-Alignment-Module-设计" class="headerlink" title="计算机视觉领域的 Alignment Module 设计"></a>计算机视觉领域的 Alignment Module 设计</h2><p>目标：将视觉特征与文本或其他模态的特征空间对齐，以实现多模态理解或提升视觉推理能力。</p><h3 id="FaithDiff"><a href="#FaithDiff" class="headerlink" title="FaithDiff"></a>FaithDiff</h3><p><img src="/images/FaithDiff.png" alt="FaithDiff alignment Module"><br>为了能够更好的在生成过程中补充 LQ 图像信息，需要将 LQ 信息注入到模型的生成过程中，但是由于 LQ 图像和 noisy latnet $x_t^{HQ}$ 之间存在 gap，直接相加是不大合理的，所以设计 <code>Alignment Module</code> 将 LQ 图像和 $x_t^{HQ}$ 进行对齐，然后输入到模型中。<br>具体来说，FaithDiff 中的 Alignment Module 设计如下：</p><script type="math/tex; mode=display">\begin{align}f_t^x &= \text{Conv}(x_t^{HQ}), \\f^m &= \text{Conv}(f^{LQ}), \\f_t^c &= \text{Concat}(f_t^x, f^m), \\\text{Trans}(f_t^c) &= \mathcal{T}_2(\mathcal{T}_1(f_t^c)), \\f_t^a &= \text{Linear}(\text{Trans}(f_t^c) + f_t^x),\end{align}</script><p>其中 $\mathcal{T}$ 是 Transformer Block, 对应的 <a href="https://github.com/JyChen9811/FaithDiff/issues/16">Alignment Module</a> 的代码位置</p><h3 id="IP-Adapter"><a href="#IP-Adapter" class="headerlink" title="IP-Adapter"></a>IP-Adapter</h3><p><img src="/images/IPadapter.png" alt="IP-Adapter"></p><p>IP-Adapter 通过解耦的两个 Cross-Attention 分别融合图像信息和文本信息，其中图像信息通过 <code>Image-Conditioned Attention</code> 进行融合，文本信息通过 <code>Text-Conditioned Attention</code> 进行融合。这种方式不会让图像和文本信息相互干扰，在信息传递的过程中可以依次提取所需要的图像和文本信息。</p><h3 id="DAEFR"><a href="#DAEFR" class="headerlink" title="DAEFR"></a>DAEFR</h3><p><img src="/images/DAEFR.png" alt="DAEFR"></p><p>DAEFR 采用 CLIP 的方式，在 (b) Association Stage 对齐 LQ 和 HQ，后续采用 Attention 机制将 LQ 和 HQ 信息进行融合。</p><h2 id="参考论文"><a href="#参考论文" class="headerlink" title="参考论文"></a>参考论文</h2><ul><li><a href="https://arxiv.org/abs/2411.18824">FaithDiff: Unleashing Diffusion Models for Faithful Text-to-Image Generation</a></li><li><a href="https://arxiv.org/abs/2308.06721">IP-Adapter: Text Compatible Image Prompt Adapter for Text-to-Image Diffusion Models</a></li><li><a href="https://arxiv.org/pdf/2308.07314">DAEFR: DUAL ASSOCIATED ENCODER FOR FACE RESTORATION</a></li></ul>]]></content>
      
      
      <categories>
          
          <category> Learning </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Module </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Hello World</title>
      <link href="/2025/08/17/hello-world/"/>
      <url>/2025/08/17/hello-world/</url>
      
        <content type="html"><![CDATA[<p>欢迎来到我的博客！这是第一篇文章。</p><span id="more"></span><p>这里是文章的详细内容…</p>]]></content>
      
      
      <categories>
          
          <category> diary </category>
          
      </categories>
      
      
        <tags>
            
            <tag> test </tag>
            
        </tags>
      
    </entry>
    
    
  
  
</search>
