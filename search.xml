<?xml version="1.0" encoding="utf-8"?>
<search> 
  
  
    
    <entry>
      <title>Alignment Module</title>
      <link href="/2025/08/17/AlignmentModule/"/>
      <url>/2025/08/17/AlignmentModule/</url>
      
        <content type="html"><![CDATA[<h2 id="计算机视觉领域的-Alignment-Module-设计"><a href="#计算机视觉领域的-Alignment-Module-设计" class="headerlink" title="计算机视觉领域的 Alignment Module 设计"></a>计算机视觉领域的 Alignment Module 设计</h2><p>目标：将视觉特征与文本或其他模态的特征空间对齐，以实现多模态理解或提升视觉推理能力。</p><h3 id="FaithDiff"><a href="#FaithDiff" class="headerlink" title="FaithDiff"></a>FaithDiff</h3><p><img src="/images/FaithDiff.png" alt="FaithDiff alignment Module"><br>为了能够更好的在生成过程中补充 LQ 图像信息，需要将 LQ 信息注入到模型的生成过程中，但是由于 LQ 图像和 noisy latnet $x_t^{HQ}$ 之间存在 gap，直接相加是不大合理的，所以设计 <code>Alignment Module</code> 将 LQ 图像和 $x_t^{HQ}$ 进行对齐，然后输入到模型中。<br>具体来说，FaithDiff 中的 Alignment Module 设计如下：</p><script type="math/tex; mode=display">\begin{align}f_t^x &= \text{Conv}(x_t^{HQ}), \\f^m &= \text{Conv}(f^{LQ}), \\f_t^c &= \text{Concat}(f_t^x, f^m), \\\text{Trans}(f_t^c) &= \mathcal{T}_2(\mathcal{T}_1(f_t^c)), \\f_t^a &= \text{Linear}(\text{Trans}(f_t^c) + f_t^x),\end{align}</script><p>其中 $\mathcal{T}$ 是 Transformer Block, 对应的 <a href="https://github.com/JyChen9811/FaithDiff/issues/16">Alignment Module</a> 的代码位置</p><h3 id="IP-Adapter"><a href="#IP-Adapter" class="headerlink" title="IP-Adapter"></a>IP-Adapter</h3><p><img src="/images/IPadapter.png" alt="IP-Adapter"></p><p>IP-Adapter 通过解耦的两个 Cross-Attention 分别融合图像信息和文本信息，其中图像信息通过 <code>Image-Conditioned Attention</code> 进行融合，文本信息通过 <code>Text-Conditioned Attention</code> 进行融合。这种方式不会让图像和文本信息相互干扰，在信息传递的过程中可以依次提取所需要的图像和文本信息。</p><h3 id="DAEFR"><a href="#DAEFR" class="headerlink" title="DAEFR"></a>DAEFR</h3><p><img src="/images/DAEFR.png" alt="DAEFR"></p><p>DAEFR 采用 CLIP 的方式，在 (b) Association Stage 对齐 LQ 和 HQ，后续采用 Attention 机制将 LQ 和 HQ 信息进行融合。</p><h2 id="参考论文"><a href="#参考论文" class="headerlink" title="参考论文"></a>参考论文</h2><ul><li><a href="https://arxiv.org/abs/2411.18824">FaithDiff: Unleashing Diffusion Models for Faithful Text-to-Image Generation</a></li><li><a href="https://arxiv.org/abs/2308.06721">IP-Adapter: Text Compatible Image Prompt Adapter for Text-to-Image Diffusion Models</a></li><li><a href="https://arxiv.org/pdf/2308.07314">DAEFR: DUAL ASSOCIATED ENCODER FOR FACE RESTORATION</a></li></ul>]]></content>
      
      
      <categories>
          
          <category> Learning </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Module </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Hello World</title>
      <link href="/2025/08/17/hello-world/"/>
      <url>/2025/08/17/hello-world/</url>
      
        <content type="html"><![CDATA[<p>欢迎来到我的博客！这是第一篇文章。</p><span id="more"></span><p>这里是文章的详细内容…</p>]]></content>
      
      
      <categories>
          
          <category> diary </category>
          
      </categories>
      
      
        <tags>
            
            <tag> test </tag>
            
        </tags>
      
    </entry>
    
    
  
  
</search>
